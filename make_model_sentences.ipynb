{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "from lstm_class import RNNLM\n",
    "from bilstm_class import RNNLM_bilstm\n",
    "from rnn_class import RNNModel\n",
    "from model_functions import model_factory\n",
    "\n",
    "models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2']\n",
    "\n",
    "#load probability ranges and get steps\n",
    "rngs=np.load('prob_ranges.npy')\n",
    "steps_all=np.zeros([11,10])\n",
    "for i,rng in enumerate(rngs):\n",
    "    low=rng[0]-45\n",
    "    high=rng[1]-10\n",
    "    steps=np.linspace(low,high,10)\n",
    "    steps_all[i,:]=steps\n",
    "\n",
    "#turn on/off printing (1=on)\n",
    "print_on=1\n",
    "\n",
    "#model names\n",
    "model1_name='gpt2'\n",
    "\n",
    "#bigram and trigram models run on CPU, so gpu_id will be ignored\n",
    "model1_gpu_id=0\n",
    "\n",
    "#get probability range for model 1\n",
    "steps=steps_all[models.index(model1_name)]\n",
    "\n",
    "#sentence length\n",
    "sent_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=model_factory(model1_name,model1_gpu_id)\n",
    "\n",
    "get_model1_sent_prob=model1.sent_prob\n",
    "get_model1_word_probs=model1.word_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_low.pkl', 'rb') as file:\n",
    "    vocab_low=pickle.load(file) \n",
    "    \n",
    "with open('vocab_low_freqs.pkl', 'rb') as file:\n",
    "    vocab_low_freqs=pickle.load(file) \n",
    "\n",
    "with open('vocab_cap.pkl', 'rb') as file:\n",
    "    vocab_cap=pickle.load(file) \n",
    "    \n",
    "with open('vocab_cap_freqs.pkl', 'rb') as file:\n",
    "    vocab_cap_freqs=pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for step_ind in range(10):\n",
    "    \n",
    "    step=steps[step_ind]\n",
    "    \n",
    "    file=open(model1_name+'_level_'+str(step_ind+1)+'.txt','w')\n",
    "    \n",
    "    num_sents=0\n",
    "    while num_sents<60:\n",
    "    \n",
    "        wordi=np.arange(sent_len)\n",
    "        wordis=[]  \n",
    "        for i in range(1000):\n",
    "            random.shuffle(wordi)\n",
    "            wordis=wordis+list(wordi)\n",
    "\n",
    "        vocab_low_freqs1=np.ones([len(vocab_low_freqs)])/len(vocab_low_freqs)\n",
    "        vocab_cap_freqs1=np.ones([len(vocab_cap_freqs)])/len(vocab_cap_freqs)\n",
    "\n",
    "        words1=list(np.random.choice(vocab_cap, 1, p=vocab_cap_freqs1)) + list(np.random.choice(vocab_low, sent_len-1, p=vocab_low_freqs1, replace=False))\n",
    "                        \n",
    "        words1o=words1.copy()\n",
    "\n",
    "        sent1=' '.join(words1)\n",
    "        \n",
    "        sent1_last=sent1\n",
    "\n",
    "        model1_sent1_prob=get_model1_sent_prob(sent1)\n",
    "\n",
    "        if print_on==1:\n",
    "            print('Target: '+str(step))\n",
    "            print('Current: '+str(model1_sent1_prob))\n",
    "            print(sent1)\n",
    "            print('\\n')\n",
    "\n",
    "        probs_all_list=[model1_sent1_prob]\n",
    "\n",
    "        cycle=0\n",
    "        \n",
    "   \n",
    "        for samp in range(10000):       \n",
    "        \n",
    "        \n",
    "        \n",
    "            if np.abs(model1_sent1_prob-step) < 1:\n",
    "\n",
    "                file.write(sent1+'.')\n",
    "                file.write('\\n')\n",
    "\n",
    "                num_sents+=1\n",
    "\n",
    "                break   \n",
    "                \n",
    "            elif cycle==sent_len:\n",
    "                break\n",
    "\n",
    "            elif model1_sent1_prob - step > 1:\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            if samp%sent_len==0:\n",
    "                cycle=0\n",
    "\n",
    "            words1o=words1.copy()\n",
    "\n",
    "            wordi=int(wordis[samp])\n",
    "\n",
    "            cur_word1=words1[wordi]\n",
    "\n",
    "            if wordi==0:\n",
    "                vocab=vocab_cap\n",
    "            else:\n",
    "                vocab=vocab_low\n",
    "\n",
    "            model1_word1_probs = get_model1_word_probs(words1,wordi)\n",
    "\n",
    "\n",
    "            if len(model1_word1_probs)==2:\n",
    "                model1_word1_inds=model1_word1_probs[1]\n",
    "                model1_word1_probs=model1_word1_probs[0]\n",
    "            else:\n",
    "                model1_word1_inds=np.arange(len(vocab))\n",
    "\n",
    "            words1=words1o.copy()\n",
    "\n",
    "            word1_list=[vocab[w] for w in model1_word1_inds]\n",
    "\n",
    "#             model1_word1_probs=model1_word1_probs/np.sum(model1_word1_probs)\n",
    "        \n",
    "            word1_tops=[word1_list[vp] for vp in np.argsort(model1_word1_probs)[::-1][:50]] + [cur_word1]\n",
    "            \n",
    "     \n",
    " \n",
    "\n",
    "            model1_sent1_probs=[]\n",
    "            model1_sent1_prob_diffs=[]\n",
    "\n",
    "            sent1_conts12=[]\n",
    "            sent2_conts21=[]\n",
    "\n",
    "            for word1 in word1_tops:\n",
    "\n",
    "                words1t=words1o.copy()\n",
    "\n",
    "                words1t[wordi]=word1\n",
    "\n",
    "                sent1t=' '.join(words1t)\n",
    "                \n",
    "                model1_sent1t_prob=get_model1_sent_prob(sent1t)\n",
    "\n",
    "                model1_sent1_probs.append(model1_sent1t_prob)\n",
    "                \n",
    "                if model1_sent1t_prob - step <= 1:\n",
    "                    break\n",
    "                \n",
    "                #model1_sent1_prob_diffs.append(np.abs(model1_sent1t_prob-step))\n",
    "                \n",
    "              \n",
    "            #aa=np.argmin(model1_sent1_prob_diffs)          \n",
    "            #new_word1=word1_tops[aa]\n",
    "            \n",
    "            new_word1=word1\n",
    "\n",
    "            new_word1o=new_word1\n",
    "\n",
    "            words1[wordi]=new_word1.upper()\n",
    "\n",
    "            sent1p=' '.join(words1)\n",
    "\n",
    "            words1[wordi]=new_word1.lower()\n",
    "            if wordi==0 or new_word1o[0].isupper():\n",
    "                words1[wordi]=new_word1.lower().capitalize()\n",
    "\n",
    "            sent1=' '.join(words1)\n",
    "            \n",
    "            if sent1==sent1_last:\n",
    "                cycle+=1\n",
    "\n",
    "            sent1_last=sent1\n",
    "\n",
    "            model1_sent1_prob=model1_sent1t_prob\n",
    "\n",
    "            probs_all_list.append(model1_sent1_prob)\n",
    "\n",
    "            if print_on==1:\n",
    "                print('Target: '+str(step))\n",
    "                print('Current: '+str(model1_sent1_prob))\n",
    "                print(sent1p)\n",
    "                print('\\n')\n",
    "\n",
    "            \n",
    "            \n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
