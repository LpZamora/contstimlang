{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import pickle\n",
    "plt.rcParams['figure.dpi']= 200\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_stim=pd.read_excel('contstim_pilot_n11_spreadsheet.xlsx')\n",
    "task_data=pd.read_csv('data_exp_22452-v9_task-ax2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2','human_probs']\n",
    "    \n",
    "events=list(task_data['Event Index'])\n",
    "start_inds=[i for i,e in enumerate(events) if e=='1']\n",
    "\n",
    "fitsets=[]\n",
    "\n",
    "all_sents=[]\n",
    "\n",
    "item_responses=dict()\n",
    "\n",
    "for i,start_ind in enumerate(start_inds):\n",
    "\n",
    "    setnum=task_data['counterbalance-o1ql'][start_ind]\n",
    "\n",
    "    if i==12:\n",
    "        setnum='set 12'\n",
    "\n",
    "    if i<len(start_inds)-1:\n",
    "        responses_list=list(task_data['Response'][start_ind:start_inds[i+1]])\n",
    "    else:\n",
    "        responses_list=list(task_data['Response'][start_ind:])\n",
    "\n",
    "    responses_list=[r for r in responses_list if str(r)!='nan']\n",
    "    \n",
    "    sent1_list=list(task_stim['sentence1_'+setnum])[1:]\n",
    "    sent2_list=list(task_stim['sentence2_'+setnum])[1:]\n",
    "\n",
    "    item_ids=[]\n",
    "    \n",
    "    for t in range(110):\n",
    "        \n",
    "        sent1=sent1_list[t]\n",
    "        sent2=sent2_list[t]\n",
    "\n",
    "        sents=[sent1,sent2]\n",
    "        sents_unsort=[sent1,sent2]     \n",
    "        sents.sort()\n",
    "        item_id='_'.join(sents)\n",
    "        \n",
    "        \n",
    "        \n",
    "        response=responses_list[t]\n",
    "        \n",
    "        if item_id in item_ids:\n",
    "            continue\n",
    "            \n",
    "        item_ids.append(item_id)\n",
    "            \n",
    "        if item_id not in item_responses:\n",
    "            item_responses[item_id]=[sents_unsort.index(response)]\n",
    "        else:\n",
    "            item_responses[item_id].append(sents_unsort.index(response))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prob_ceilings=dict()\n",
    "for item in item_responses:\n",
    "    \n",
    "    resp_list=item_responses[item]\n",
    "    \n",
    "    p1=np.sum(resp_list)/len(resp_list)\n",
    "    p2=1-np.sum(resp_list)/len(resp_list)\n",
    "    \n",
    "    p_choice_1=p2\n",
    "    \n",
    "    if p_choice_1==1:\n",
    "        p_choice_1=.999\n",
    "    \n",
    "    if p_choice_1==0:\n",
    "        p_choice_1=.001\n",
    "    \n",
    "    s1a_b=-np.log(1-p_choice_1)/p_choice_1*10\n",
    "       \n",
    "    lp1=-100+s1a_b/2\n",
    "    lp2=-100-s1a_b/2\n",
    "    \n",
    "    item_prob_ceilings[item]=[lp1,lp2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2','human_probs']\n",
    "\n",
    "prob_dict=dict()\n",
    "for model_name in models[:11]:\n",
    "    f = open(model_name+'_expt1_sentence_probs.pkl','rb')\n",
    "    dict1=pickle.load(f)\n",
    "    prob_dict[model_name]=dict1\n",
    "    \n",
    "    \n",
    "events=list(task_data['Event Index'])\n",
    "start_inds=[i for i,e in enumerate(events) if e=='1']\n",
    "\n",
    "fitsets=[]\n",
    "\n",
    "all_sents=[]\n",
    "\n",
    "item_responses=dict()\n",
    "\n",
    "for i,start_ind in enumerate(start_inds):\n",
    "\n",
    "    setnum=task_data['counterbalance-o1ql'][start_ind]\n",
    "\n",
    "    if i==12:\n",
    "        setnum='set 12'\n",
    "\n",
    "    sub=task_data['Participant External Session ID'][start_ind]\n",
    "\n",
    "    model1_list=list(task_stim['sentence1_model_'+setnum])[1:]\n",
    "    model2_list=list(task_stim['sentence2_model_'+setnum])[1:]\n",
    "    sent1_list=list(task_stim['sentence1_'+setnum])[1:]\n",
    "    sent2_list=list(task_stim['sentence2_'+setnum])[1:]\n",
    "\n",
    "    if setnum=='set 1':\n",
    "        source_list=list(task_stim['source'])[1:]\n",
    "\n",
    "    else:\n",
    "        source_list=list(task_stim['source_'+setnum])[1:]\n",
    "\n",
    "    if i<len(start_inds)-1:\n",
    "        responses_list=list(task_data['Response'][start_ind:start_inds[i+1]])\n",
    "\n",
    "    else:\n",
    "        responses_list=list(task_data['Response'][start_ind:])\n",
    "\n",
    "    responses_list=[r for r in responses_list if str(r)!='nan']\n",
    "\n",
    "    item_ids=[]\n",
    "\n",
    "    fitset=[]\n",
    "    \n",
    "    for t in range(110):\n",
    "\n",
    "        source=source_list[t]\n",
    "\n",
    "        model1=model1_list[t]\n",
    "        model2=model2_list[t]\n",
    "        sent1=sent1_list[t]\n",
    "        sent2=sent2_list[t]\n",
    "        \n",
    "        all_sents.append(sent1)\n",
    "        all_sents.append(sent2)\n",
    "\n",
    "        model1_name=model1[:-2]\n",
    "        model2_name=model2[:-2]        \n",
    "\n",
    "        model_ind=models.index(model1_name)\n",
    "\n",
    "        sents=[sent1,sent2]\n",
    "        sents_unsort=[sent1,sent2]     \n",
    "        sents.sort()\n",
    "        item_id='_'.join(sents)\n",
    "        \n",
    "        response=responses_list[t]\n",
    "        \n",
    "        if item_id in item_ids:\n",
    "            continue\n",
    "            \n",
    "        if item_id not in item_responses:\n",
    "            item_responses[item_id]=[sents_unsort.index(response)]\n",
    "        else:\n",
    "            item_responses[item_id].append(sents_unsort.index(response))\n",
    "        \n",
    "        item_ids.append(item_id)\n",
    "\n",
    "        response_ind=[sent1,sent2].index(response)     \n",
    "        \n",
    "        for model_name in models[:11]:#[model1_name]\n",
    "\n",
    "            log_p1=prob_dict[model_name][sent1]\n",
    "            log_p2=prob_dict[model_name][sent2]\n",
    "\n",
    "            fitset.append([model_name,log_p1,log_p2,response_ind])\n",
    "            \n",
    "        log_human_p1=item_prob_ceilings[item_id][0]\n",
    "        log_human_p2=item_prob_ceilings[item_id][1]\n",
    "        \n",
    "        fitset.append(['human_probs',log_human_p1,log_human_p2,response_ind])\n",
    "        \n",
    "    fitsets.append(fitset)\n",
    "\n",
    "fitsets_all=[]\n",
    "for fitset in fitsets:\n",
    "    fitsets_all+=fitset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "minps=[]\n",
    "for m in models:\n",
    "    m=np.min([np.min([trial[1],trial[2]]) for trial in fitsets_all if trial[0]==m])\n",
    "    minps.append(m)\n",
    "    \n",
    "minps=np.abs(minps)\n",
    "\n",
    "\n",
    "maxps=[]\n",
    "for m in models:\n",
    "    m=np.max([np.max([trial[1],trial[2]]) for trial in fitsets_all if trial[0]==m])\n",
    "    maxps.append(m)\n",
    "    \n",
    "maxps=np.abs(maxps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overflow within exponentials when calculating probabilities, we'll use torch.logsumexp where log(exp(x)+1) is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(1+exp(x)) | direct implementation: tensor([ 0.0000, 50.0000,  0.3133,  0.6931,  1.3133, 50.0000,     inf])\n",
      "log(1+exp(x)) | with logsumexp: tensor([  0.0000,  50.0000,   0.3133,   0.6931,   1.3133,  50.0000, 100.0000])\n",
      "log(1/(1+exp(x))) | direct implementation: tensor([  0.0000, -50.0000,  -0.3133,  -0.6931,  -1.3133, -50.0000,     -inf])\n",
      "log(1/(1+exp(x))) | with logsumexp: tensor([  -0.0000,  -50.0000,   -0.3133,   -0.6931,   -1.3133,  -50.0000,\n",
      "        -100.0000])\n",
      "log(1 - 1/(1+exp(x))) | direct implementation: tensor([   -inf,  0.0000, -1.3133, -0.6931, -0.3133,  0.0000,  0.0000])\n",
      "log(1 - 1/(1+exp(x))) | with logsumexp: tensor([-100.0000,    0.0000,   -1.3133,   -0.6931,   -0.3133,    0.0000,\n",
      "           0.0000])\n"
     ]
    }
   ],
   "source": [
    "# this is mathemathically eqivalent to torch.log(1+torch.exp(x)) but it doesn't overflow when x is big.\n",
    "log_1_plus_exp_x=lambda x: torch.logsumexp(torch.stack((x,torch.zeros_like(x)),dim=-1),dim=1)\n",
    "\n",
    "# this is mathemathically equivalent to log(1/(1+exp(x)))\n",
    "log_p=lambda x: -log_1_plus_exp_x(x) \n",
    "\n",
    "# this is mathemathically equivalent to log(1 - 1/(1+exp(x)) )\n",
    "log_1_minus_p=lambda x: x+log_p(x)\n",
    "\n",
    "x=torch.tensor([-100.0,50.0,-1.0,0.0,1.0,50.0,100.0])\n",
    "print('log(1+exp(x)) | direct implementation:', torch.log(1+torch.exp(x)))\n",
    "print('log(1+exp(x)) | with logsumexp:', log_1_plus_exp_x(x))\n",
    "\n",
    "print('log(1/(1+exp(x))) | direct implementation:', torch.log(1/(1+torch.exp(x))))\n",
    "print('log(1/(1+exp(x))) | with logsumexp:', log_p(x))\n",
    "\n",
    "print('log(1 - 1/(1+exp(x))) | direct implementation:', torch.log(1-1/(1+torch.exp(x))))\n",
    "print('log(1 - 1/(1+exp(x))) | with logsumexp:', log_1_minus_p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelToHumanDecision():\n",
    "    def _set_initial_parameters(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __init__(self,model_name_list,parameters=None,device=None):\n",
    "        if device is None:\n",
    "            device='cpu'\n",
    "        \n",
    "        self.device=torch.device(device)\n",
    "        self.model_name_list=model_name_list\n",
    "        self.n_models=len(model_name_list)\n",
    "        \n",
    "        if parameters is None:\n",
    "            self.parameters=self._initial_parameters()\n",
    "        else:\n",
    "            self.parameters={key:torch.tensor(value,device=self.device,dtype=torch.float64) for (key,value) in parameters.items()}\n",
    "\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def decision_NLL(self,log_p1,log_p2,model=None):\n",
    "        \n",
    "        log_p1=torch.as_tensor(log_p1,device=self.device,dtype=torch.float64)\n",
    "        log_p2=torch.as_tensor(log_p2,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        if model is None: # evaluate all models. # log_p1, log_p2 (n_models,n_sentence_pairs)\n",
    "            assert log_p1.ndim==2 and log_p1.shape[0]==self.n_models and log_p2.ndim==3 and log_p2.shape[0]==self.n_models \n",
    "            slicer=...\n",
    "        elif type(model) is str: # one particular model specified by its name\n",
    "            slicer=self.model_name_list.index(model)\n",
    "        elif type(model) is int: # one particular model specified by its index\n",
    "            slicer=model\n",
    "        elif type(model) is list: # a list of model names\n",
    "            slicer=torch.tensor([self.model_name_list.index(m) for m in model])\n",
    "        else:\n",
    "            raise \n",
    "        cur_parameters={}\n",
    "        \n",
    "#         print(self.parameters.items())\n",
    "#         sys.e\n",
    "        \n",
    "        for par_name, par in self.parameters.items():\n",
    "            if par.nelement()==1:\n",
    "                cur_parameters[par_name]=par\n",
    "            else:\n",
    "                cur_parameters[par_name]=par[slicer]\n",
    "        return self._f(log_p1,log_p2,cur_parameters)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        numpy_parameters={}\n",
    "        for par_name, par in self.parameters.items():\n",
    "            if par.nelement()==1:\n",
    "                numpy_parameters[par_name]=par.item()\n",
    "            else:\n",
    "                numpy_parameters[par_name]=par.detach().cpu().numpy()\n",
    "        return numpy_parameters\n",
    "\n",
    "class FixedWidthSquashing(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.tensor(10.0,device=self.device)\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=1.0\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))        \n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL\n",
    "\n",
    "    \n",
    "class FixedWidthSquashingVariableGamma(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        return parameters\n",
    "    \n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=1.0\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "        #log_p1_corrected=width*torch.log(1+math.e**((log_p1+squash_threshold)/width))-squash_threshold\n",
    "        #log_p2_corrected=width*torch.log(1+math.e**((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL\n",
    "\n",
    "class VariableWidthSquashing(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.tensor(10.0,device=self.device)\n",
    "        parameters['width']=torch.ones(self.n_models,device=self.device)        \n",
    "        return parameters\n",
    "    \n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=torch.nn.Softplus()(cur_parameters['width'])+1e-1\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "#         log_p1_corrected=width*torch.log(1+torch.exp((log_p1+squash_threshold)/width))-squash_threshold\n",
    "#         log_p2_corrected=width*torch.log(1+torch.exp((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "\n",
    "\n",
    "class VariableWidthSquashingVariableGamma(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        parameters['width']=torch.ones(self.n_models,device=self.device)\n",
    "\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=torch.nn.Softplus()(cur_parameters['width'])+1e-1\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "#         log_p1_corrected=width*torch.log(1+math.e**((log_p1+squash_threshold)/width))-squash_threshold\n",
    "#         log_p2_corrected=width*torch.log(1+math.e**((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "    \n",
    "\n",
    "class VariableGammaNoSquash(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        s1a_b = log_p1 - log_p2\n",
    "        p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "        p2=1-p1\n",
    "        choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "    \n",
    "class SquashedSoftmax(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        parameters['eta']=torch.ones(self.n_models,device=self.device)*(0.0)\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        eta=cur_parameters['eta']\n",
    "        \n",
    "        denominator=torch.logsumexp(torch.stack([log_p1/gamma,torch.ones_like(log_p1)*eta,log_p2/gamma,torch.ones_like(log_p2)*eta],dim=-1),dim=-1)\n",
    "        log_p1 = torch.logsumexp(torch.stack([log_p1/gamma,torch.ones_like(log_p1)*eta],dim=-1),dim=-1)-denominator\n",
    "        log_p2 = torch.logsumexp(torch.stack([log_p2/gamma,torch.ones_like(log_p2)*eta],dim=-1),dim=-1)-denominator\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "loss: tensor(11.1546, grad_fn=<AddBackward0>)\n",
      "squashes tensor([172.6353, 158.2039, 186.6036, 191.4571, 141.2743, 151.7397, 150.0234,\n",
      "        151.1320, 147.1514, 134.0681, 128.9228, 134.5733], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4544, grad_fn=<AddBackward0>)\n",
      "squashes tensor([150.0433, 137.7759, 196.2826,  96.1775,  92.9848,  98.0878,  94.5247,\n",
      "        102.9988,  92.9376,  87.3188,  92.8564, 147.2656], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([26.9722, 28.4508, 39.3416, 36.6925, 31.0479, 31.2035, 32.6404, 30.8057,\n",
      "        32.1388, 30.9679, 31.0270, 34.4768], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4466, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.2775, 138.7478, 196.9647,  96.8180,  89.8488,  97.3352,  93.4415,\n",
      "        100.6510,  92.9016,  85.5262,  93.4798, 147.4035], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.9884, 28.9694, 45.8873, 35.3469, 29.2037, 29.7165, 32.0823, 28.9066,\n",
      "        31.3234, 29.4020, 31.3056, 36.3086], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4440, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1216, 139.0466, 197.4369,  95.6953,  88.2478,  93.3904,  92.6099,\n",
      "         99.6427,  92.3926,  84.5988,  93.9679, 147.5617], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7994, 29.2049, 49.6339, 33.8883, 27.3460, 27.6813, 31.4942, 27.6394,\n",
      "        30.7551, 28.2788, 31.5601, 36.6271], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4430, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1114, 139.1486, 197.7821,  94.8707,  87.7770,  90.4960,  91.6428,\n",
      "         99.3409,  92.1317,  84.3249,  94.6945, 147.7251], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7873, 29.2843, 51.9144, 32.7971, 26.6904, 25.2470, 30.8733, 27.2502,\n",
      "        30.4744, 27.9209, 31.8566, 36.6571], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4427, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1747, 198.0499,  94.3565,  87.7042,  89.1200,  90.8192,\n",
      "         99.2900,  92.0324,  84.2773,  98.0726, 147.8863], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3046, 53.3137, 32.1529, 26.5876, 23.9959, 30.2758, 27.1848,\n",
      "        30.3688, 27.8584, 32.5992, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1796, 198.2667,  94.0913,  87.6981,  88.8287,  90.3054,\n",
      "         99.2849,  92.0031,  84.2722, 100.6184, 148.0418], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3084, 54.1565, 31.8362, 26.5790, 23.7177, 29.8598, 27.1782,\n",
      "        30.3378, 27.8518, 34.3101, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 198.4480,  93.9759,  87.6979,  88.7951,  90.0493,\n",
      "         99.2846,  91.9963,  84.2719, 100.7805, 148.1903], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3089, 54.6460, 31.7022, 26.5786, 23.6856, 29.6436, 27.1778,\n",
      "        30.3305, 27.8514, 34.5356, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 198.6033,  93.9328,  87.6979,  88.7927,  89.9428,\n",
      "         99.2846,  91.9950,  84.2719, 100.7908, 148.3314], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 54.9170, 31.6527, 26.5786, 23.6833, 29.5525, 27.1778,\n",
      "        30.3292, 27.8514, 34.5503, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 198.7388,  93.9188,  87.6979,  88.7926,  89.9047,\n",
      "         99.2846,  91.9948,  84.2719, 100.7912, 148.4655], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 55.0586, 31.6368, 26.5786, 23.6832, 29.5197, 27.1778,\n",
      "        30.3290, 27.8514, 34.5508, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 198.8589,  93.9149,  87.6979,  88.7926,  89.8929,\n",
      "         99.2846,  91.9948,  84.2719, 100.7913, 148.5927], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 55.1279, 31.6322, 26.5786, 23.6832, 29.5095, 27.1778,\n",
      "        30.3290, 27.8514, 34.5508, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 198.9666,  93.9139,  87.6979,  88.7926,  89.8896,\n",
      "         99.2846,  91.9948,  84.2719, 100.7913, 148.7137], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 55.1596, 31.6311, 26.5786, 23.6832, 29.5068, 27.1778,\n",
      "        30.3290, 27.8514, 34.5508, 36.6583], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "{'squashes': array([149.11119465, 139.18034908, 198.97795777,  93.91386679,\n",
      "        87.69785544,  88.7926001 ,  89.88947315,  99.2846165 ,\n",
      "        91.99481549,  84.27189394, 100.79125734, 148.72678913]), 'gamma': array([25.7871429 , 29.30896009, 55.16175092, 31.6310921 , 26.57863977,\n",
      "       23.6832158 , 29.50663341, 27.17782044, 30.32898546, 27.85135288,\n",
      "       34.55084805, 36.65831453])}\n",
      "total loss: tensor(7.4425, grad_fn=<AddBackward0>)\n",
      "bigram 0.62\n",
      "trigram 0.62\n",
      "rnn 0.63\n",
      "lstm 0.62\n",
      "bilstm 0.62\n",
      "bert 0.62\n",
      "bert_whole_word 0.62\n",
      "roberta 0.62\n",
      "xlm 0.62\n",
      "electra 0.62\n",
      "gpt2 0.62\n",
      "human_probs 0.61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':10.0}\n",
    "# model_class=FixedWidthSquashing\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':10.0,'width':np.ones(len(models))}\n",
    "# model_class=VariableWidthSquashing\n",
    "\n",
    "parameters={'squashes':minps,'gamma':np.ones_like(minps)*10.0}\n",
    "model_class=FixedWidthSquashingVariableGamma\n",
    "\n",
    "# parameters={'gamma':np.ones_like(minps)*10.0}\n",
    "# model_class=VariableGammaNoSquash\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':np.ones_like(minps)*10.0,'width':np.ones(len(models))}\n",
    "# model_class=VariableWidthSquashingVariableGamma\n",
    "\n",
    "# parameters=None # use defaults\n",
    "# model_class=SquashedSoftmax\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "for boot in range(1):\n",
    "    \n",
    "#     boots=np.random.choice(13, 13)\n",
    "    boots=np.arange(13)\n",
    "    \n",
    "    fitset=[]\n",
    "    for b in boots:\n",
    "        fitset+=fitsets[b]\n",
    "    \n",
    "    decision_model=model_class(model_name_list=models,parameters=parameters,device=device)\n",
    "\n",
    "    for par in decision_model.parameters.values():\n",
    "        par.requires_grad=True\n",
    "        \n",
    "    opt = optim.Adam(decision_model.parameters.values(),lr=1)\n",
    "\n",
    "    print(boot)\n",
    "    print('')\n",
    "\n",
    "    # build models by trials by sentences log-prob matrix\n",
    "    \n",
    "    log_p1=defaultdict(list)\n",
    "    log_p2=defaultdict(list)\n",
    "    response_ind=defaultdict(list)\n",
    "    \n",
    "    for trial in fitset:\n",
    "        model1_name=trial[0]\n",
    "        log_p1[model1_name].append(trial[1])\n",
    "        log_p2[model1_name].append(trial[2])\n",
    "        response_ind[model1_name].append(trial[3])\n",
    "        \n",
    "    \n",
    "    for epoch in range(1000): # for some models, one needs more than 200 epochs for convergence. I'd replace this loop with a convergence criterion.\n",
    "\n",
    "        loss = torch.tensor(0.,device=device,requires_grad = True)\n",
    "        \n",
    "        model_loss=torch.zeros((len(models)),device=device)\n",
    "        for i_model,model1_name in enumerate(models):\n",
    "            log_p_sent=decision_model.decision_NLL(log_p1[model1_name],log_p2[model1_name],model=model1_name)\n",
    "            take_by_2nd_dim=lambda x, idx: x[torch.arange(x.size(0)), idx] \n",
    "            log_p_choice=take_by_2nd_dim(log_p_sent,response_ind[model1_name])\n",
    "            model_loss[i_model]=log_p_choice.mean()\n",
    "            loss=loss+model_loss[i_model]\n",
    "            \n",
    "        if epoch%90==0:\n",
    "            print('loss:',loss)\n",
    "            for par_name, par in decision_model.parameters.items():\n",
    "                print(par_name,par)\n",
    "            print('')\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    print(decision_model.get_parameters())\n",
    "    print('total loss:',loss)\n",
    "    for i_model,model1_name in enumerate(models):\n",
    "        print('{} {:.2f}'.format(model1_name,model_loss[i_model].item()))\n",
    "    \n",
    "    squashes=list(decision_model.parameters['squashes'].data.numpy())\n",
    "    gammas=list(decision_model.parameters['gamma'].data.numpy())\n",
    "    #gammas=float(decision_model.parameters['gamma'])\n",
    "    \n",
    "    if boot==0:\n",
    "        squash_boots=[squashes]\n",
    "        gamma_boots=[gammas]\n",
    "        losses=[[model_loss[i_model].item() for i_model in range(12)]]\n",
    "    else:\n",
    "        squash_boots.append(squashes)\n",
    "        gamma_boots.append(gammas)\n",
    "        losses.append([model_loss[i_model].item() for i_model in range(12)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gT=np.array(gamma_boots).T\n",
    "sT=np.array(squash_boots).T\n",
    "\n",
    "ccs=[]\n",
    "for i in range(11):\n",
    "    \n",
    "    cc=np.corrcoef(sT[i,:],gT[i,:])[0,1]\n",
    "    ccs.append(cc)\n",
    "    \n",
    "ccs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p1['trigram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synthetic\n",
    "\n",
    "# tensor(671.4779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([129.5626, 128.7844,  84.1193,  92.4041, 111.8108, 105.3416,  83.8154,\n",
    "#         116.5818,  87.0363,  60.6492,  81.0560], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([29.8585, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n",
    "\n",
    "\n",
    "#natural\n",
    "\n",
    "# tensor(148.7837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([115.8415,  84.2844,  72.0876,  43.8699,  54.9998,  50.4821,  69.6983,\n",
    "#          49.1065,  42.4528,  34.6840,  59.5816], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([ 9.1418, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n",
    "\n",
    "\n",
    "# tensor(829.6835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([129.1968, 127.7177,  83.4297,  91.0015, 111.4391, 104.3089,  83.3092,\n",
    "#         115.3282,  85.6379,  59.8025,  79.7266], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([28.2664, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squash_boots=np.array([[136.6031, 130.6315,  88.2857, 127.1014, 124.6718, 110.4878,  84.6417,\n",
    "#         118.1435, 107.7737,  63.0790,  79.9143],\n",
    "#               [137.9003, 125.7105,  84.5635, 127.1772, 112.0871,  94.5774,  78.6344,\n",
    "#         114.0863,  95.4273,  58.2541,  79.6323],\n",
    "#               [131.8761, 133.7181, 147.7142, 143.2530, 110.6293, 134.2203,  83.7578,\n",
    "#         139.0220,  82.7407,  66.7261,  79.2919],\n",
    "#               [139.6443, 135.6945,  80.5810,  94.8058, 116.6113, 103.0531,  87.4392,\n",
    "#         119.7775,  81.2322,  60.9193,  81.1773],\n",
    "#               [132.4967, 128.7608,  92.4549,  91.8489, 110.4346, 104.1544,  80.5317,\n",
    "#         126.0785, 124.9601,  57.4880,  76.9285],\n",
    "#               [128.2988, 112.9426,  80.0811,  90.9844, 111.0652, 115.8396,  56.3730,\n",
    "#          78.9889, 120.2621,  29.6331,  61.9582],\n",
    "#               [127.7181, 132.9688, 148.8201,  94.7272, 109.7225,  87.5404,  81.3132,\n",
    "#         115.8013, 116.9241,  64.7583,  73.5550],\n",
    "#               [120.8540, 116.8421, 135.4461,  88.5892, 124.1079, 133.7935,  86.1704,\n",
    "#         100.1683,  92.7386,  49.7565,  79.4477],\n",
    "#               [125.4391, 114.5180,  82.5459,  87.4416, 110.8198,  93.8739,  63.4568,\n",
    "#         117.9814,  83.9064,  57.2624,  77.2107],\n",
    "#               [129.6447, 129.3590,  86.6444,  92.5276, 109.5141, 105.0256,  65.8152,\n",
    "#         117.5682, 125.8277,  59.4612,  77.8789]])\n",
    "\n",
    "s=squash_boots\n",
    "\n",
    "squash_boots=np.array(losses).T\n",
    "squash_boots.sort()\n",
    "squash_boots=squash_boots.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squash_boots=squash_boots.reshape([10,11])\n",
    "\n",
    "\n",
    "\n",
    "x=np.arange(11)*2\n",
    "# plt.bar(x-0.2, maxps, width=0.1, color=[1,0,0])\n",
    "plt.bar(x-0.1, squash_boots[0], width=0.1, color=[0,0,1])\n",
    "plt.bar(x, squash_boots[1], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.1, squash_boots[2], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.2, squash_boots[3], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.3, squash_boots[4], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.4, squash_boots[5], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.5, squash_boots[6], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.6, squash_boots[7], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.7, squash_boots[8], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.8, squash_boots[9], width=0.1, color=[0,0,1])\n",
    "# plt.bar(x+0.9, minps, width=0.1, color=[1,0,0])\n",
    "\n",
    "# plt.ylabel('Squash Thresholds')\n",
    "plt.ylabel('Negative log likelihood')\n",
    "plt.xticks(x,models,rotation=70)\n",
    "\n",
    "# plt.ylim([800,950])\n",
    "\n",
    "legs=['Min/Max baseline','Squash thresholds']\n",
    "# plt.legend(legs,bbox_to_anchor=(1, 0.3, 0.2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=squash_boots.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=np.array([f.sort() for f in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_boots=d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist=list(set(all_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('test_sents_expt1_first13subs.txt','w')\n",
    "for s in slist:\n",
    "    file.write(s)\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model.parameters['squashes'].data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sent1,sent2].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=0\n",
    "a=0\n",
    "for trial in fitset:\n",
    "    \n",
    "    if trial[0]=='electra':\n",
    "        \n",
    "        a+=1\n",
    "    \n",
    "        pa=trial[1]\n",
    "        pb=trial[2]\n",
    "        c=trial[3]\n",
    "\n",
    "        if c==0 and pa>pb:\n",
    "            g+=1\n",
    "        elif c==1 and pb>pa:\n",
    "            g+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g/len(fitset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(item_prob_ceilings[item_id][1])==-math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
