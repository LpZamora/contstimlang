{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.dpi']= 200\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data_csv='data_exp_22452-v9_task-ax2v.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 70 within-subject repeating trials.\n"
     ]
    }
   ],
   "source": [
    "def prepare_tidy_protocol(csv_path,do_remove_within_subject_repetitions=True):\n",
    "    df=pd.read_csv(csv_path)\n",
    "    \n",
    "    df=df.loc[df.Response.notna(),:] #drop non-response lines\n",
    "    df=df.rename(columns={'source':'source_set 1'}) # fix a mistake in model naming\n",
    "    df=df.rename(columns={'counterbalance-o1ql':'set_num'})\n",
    "\n",
    "    # transform set columns to trial columns\n",
    "    p = re.compile('(.+)_set \\d+')\n",
    "    set_columns=[s for s in list(df.columns) if p.match(s)]\n",
    "    columns_to_keep=['Participant External Session ID','Event Index','Reaction Time','Response','set_num']+set_columns\n",
    "    columns_to_drop=list(np.setdiff1d(df.columns,columns_to_keep))\n",
    "    df=df.drop(columns=columns_to_drop)\n",
    "    columns_to_build=list(np.unique([p.findall(s)[0] for s in set_columns]))\n",
    "    for index,row in df.iterrows():\n",
    "        cur_set=row['set_num']\n",
    "        for c in columns_to_build:\n",
    "            df.loc[index,c]=df.loc[index,c+'_'+cur_set]\n",
    "    df=df.drop(columns=set_columns+['set_num'])\n",
    "\n",
    "    # make sure the sentence pairs are alphabetically sorted\n",
    "    def sort_sentence_pairs(df1):    \n",
    "        flip_dict={'sentence1':'sentence2','sentence2':'sentence1',\n",
    "                   'sentence1_model':'sentence2_model','sentence2_model':'sentence1_model'}\n",
    "        df2=df1.copy()    \n",
    "        for index, row in df2.iterrows():\n",
    "            if row['sentence1']>row['sentence2']: # a flip is needed\n",
    "                for old_col, new_col in flip_dict.items():\n",
    "                    df2.loc[index,new_col]=df1.loc[index,old_col]\n",
    "        return df2\n",
    "    df=sort_sentence_pairs(df)\n",
    "\n",
    "    # separate models and levels\n",
    "    p=re.compile('(.+)_(\\d+)')\n",
    "    df['sentence1_model_name']=[p.findall(s)[0][0] for s in df['sentence1_model']]\n",
    "    df['sentence2_model_name']=[p.findall(s)[0][0] for s in df['sentence2_model']]\n",
    "    df['sentence1_model_level']=[int(p.findall(s)[0][1]) for s in df['sentence1_model']]\n",
    "    df['sentence2_model_level']=[int(p.findall(s)[0][1]) for s in df['sentence2_model']]\n",
    "    df=df.drop(columns=['sentence1_model','sentence2_model'])\n",
    "\n",
    "    # mark choice indecis\n",
    "    for index,row in df.iterrows():\n",
    "        df.loc[index,'Choice']=[row.sentence1, row.sentence2].index(row.Response)\n",
    "\n",
    "    df['sentence_pair_id']=[s1+'_'+s2 for s1,s2 in zip(df.sentence1, df.sentence2)]\n",
    "\n",
    "    # renumber subjects\n",
    "    df.drop(columns='subject') # there's some issue here    \n",
    "    uq_subjects, ind, unique_inverse = np.unique(df['Participant External Session ID'], return_index=True,return_inverse=True)\n",
    "    uq_subjects=list(uq_subjects[np.argsort(ind)]) # unique subjects by order of appearance    \n",
    "    df['subject']=[uq_subjects.index(s) for s in df['Participant External Session ID']]\n",
    "                   \n",
    "    # optionally, remove all but first occurance of each sentence pair within a subject    \n",
    "    if do_remove_within_subject_repetitions:\n",
    "        def remove_within_subject_repetitions(df1):\n",
    "            # keep only the first appearance of each sentence pair within a subject\n",
    "            _,unique_indices=np.unique(df1.sentence_pair_id,return_index=True)\n",
    "            df2=df1.loc[np.in1d(np.arange(len(df1)),unique_indices),:]    \n",
    "            return df2\n",
    "        old_length=len(df)\n",
    "        df=df.groupby('subject').apply(remove_within_subject_repetitions)\n",
    "        print(\"removed {} within-subject repeating trials.\".format(old_length-len(df)))\n",
    "        \n",
    "    df=df.set_index(['subject','trial']).sort_values(by=['subject','trial'],axis=0).reset_index()\n",
    "    return df\n",
    "protocol=prepare_tidy_protocol(task_data_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1360 total trials with 605 sentence pairs and 13 subjects.\n"
     ]
    }
   ],
   "source": [
    "n_total_trials=len(protocol)\n",
    "n_sentence_pairs=len(np.unique(protocol['sentence_pair_id']))\n",
    "n_subjects=len(np.unique(protocol['Participant External Session ID']))\n",
    "print(\"loaded {} total trials with {} sentence pairs and {} subjects.\".format(n_total_trials,n_sentence_pairs,n_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>Event Index</th>\n",
       "      <th>Participant External Session ID</th>\n",
       "      <th>Reaction Time</th>\n",
       "      <th>Response</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence1_model_name</th>\n",
       "      <th>sentence2_model_name</th>\n",
       "      <th>sentence1_model_level</th>\n",
       "      <th>sentence2_model_level</th>\n",
       "      <th>Choice</th>\n",
       "      <th>sentence_pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>5812.220</td>\n",
       "      <td>What public schools teach their students is co...</td>\n",
       "      <td>I can not long conceal my dreadful sin</td>\n",
       "      <td>What public schools teach their students is co...</td>\n",
       "      <td>internet</td>\n",
       "      <td>xlm</td>\n",
       "      <td>xlm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I can not long conceal my dreadful sin_What pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>5300.000</td>\n",
       "      <td>And that consists of a number of factors</td>\n",
       "      <td>And that consists of a number of factors</td>\n",
       "      <td>Birmingham but the heavy duty cell one and</td>\n",
       "      <td>generator</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>And that consists of a number of factors_Birmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>9964.815</td>\n",
       "      <td>Dad of a stagnant fermentation shrimp of doubts</td>\n",
       "      <td>Dad of a stagnant fermentation shrimp of doubts</td>\n",
       "      <td>Mel causal that foothold overflowed paid Cpl a...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dad of a stagnant fermentation shrimp of doubt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>11878.520</td>\n",
       "      <td>Brisbane corp distant and finished commandos c...</td>\n",
       "      <td>Brisbane corp distant and finished commandos c...</td>\n",
       "      <td>The frustrating and bananas and the modificati...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bigram</td>\n",
       "      <td>bigram</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brisbane corp distant and finished commandos c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>12686.870</td>\n",
       "      <td>Listening those studied bails heater understan...</td>\n",
       "      <td>Hours into cults cables help arrive in mounts</td>\n",
       "      <td>Listening those studied bails heater understan...</td>\n",
       "      <td>generator</td>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hours into cults cables help arrive in mounts_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>12</td>\n",
       "      <td>106.0</td>\n",
       "      <td>214</td>\n",
       "      <td>5f919b517819d10212708607</td>\n",
       "      <td>2124.000</td>\n",
       "      <td>Activity biblical a disrupt of Nova Scotia rel...</td>\n",
       "      <td>Activity biblical a disrupt of Nova Scotia rel...</td>\n",
       "      <td>Raven toned benched homeowners boiler and hurr...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bert_whole_word</td>\n",
       "      <td>bert_whole_word</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Activity biblical a disrupt of Nova Scotia rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>12</td>\n",
       "      <td>107.0</td>\n",
       "      <td>216</td>\n",
       "      <td>5f919b517819d10212708607</td>\n",
       "      <td>1852.000</td>\n",
       "      <td>After that cry there was a deep sigh</td>\n",
       "      <td>After that cry there was a deep sigh</td>\n",
       "      <td>Be guarded in executing your ideas of right</td>\n",
       "      <td>internet</td>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>After that cry there was a deep sigh_Be guarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>12</td>\n",
       "      <td>108.0</td>\n",
       "      <td>218</td>\n",
       "      <td>5f919b517819d10212708607</td>\n",
       "      <td>1064.000</td>\n",
       "      <td>For those with understandable motives must bac...</td>\n",
       "      <td>Author of Causeway inactivity notation and exc...</td>\n",
       "      <td>For those with understandable motives must bac...</td>\n",
       "      <td>generator</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Author of Causeway inactivity notation and exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>12</td>\n",
       "      <td>109.0</td>\n",
       "      <td>220</td>\n",
       "      <td>5f919b517819d10212708607</td>\n",
       "      <td>1101.000</td>\n",
       "      <td>Stress increases bungalow wall and respiration...</td>\n",
       "      <td>Oslo slammed prerequisite unequal questioned q...</td>\n",
       "      <td>Stress increases bungalow wall and respiration...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bert</td>\n",
       "      <td>bert</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Oslo slammed prerequisite unequal questioned q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>12</td>\n",
       "      <td>110.0</td>\n",
       "      <td>222</td>\n",
       "      <td>5f919b517819d10212708607</td>\n",
       "      <td>2913.000</td>\n",
       "      <td>He was dogged in his pursuit of justice</td>\n",
       "      <td>He was dogged in his pursuit of justice</td>\n",
       "      <td>The vet arranged the busted inhaled harbour de...</td>\n",
       "      <td>generator</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>He was dogged in his pursuit of justice_The ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  trial Event Index Participant External Session ID  \\\n",
       "0           0    1.0           4        5f89a28900ebf4068239ad58   \n",
       "1           0    2.0           6        5f89a28900ebf4068239ad58   \n",
       "2           0    3.0           8        5f89a28900ebf4068239ad58   \n",
       "3           0    4.0          10        5f89a28900ebf4068239ad58   \n",
       "4           0    5.0          12        5f89a28900ebf4068239ad58   \n",
       "...       ...    ...         ...                             ...   \n",
       "1355       12  106.0         214        5f919b517819d10212708607   \n",
       "1356       12  107.0         216        5f919b517819d10212708607   \n",
       "1357       12  108.0         218        5f919b517819d10212708607   \n",
       "1358       12  109.0         220        5f919b517819d10212708607   \n",
       "1359       12  110.0         222        5f919b517819d10212708607   \n",
       "\n",
       "      Reaction Time                                           Response  \\\n",
       "0          5812.220  What public schools teach their students is co...   \n",
       "1          5300.000           And that consists of a number of factors   \n",
       "2          9964.815    Dad of a stagnant fermentation shrimp of doubts   \n",
       "3         11878.520  Brisbane corp distant and finished commandos c...   \n",
       "4         12686.870  Listening those studied bails heater understan...   \n",
       "...             ...                                                ...   \n",
       "1355       2124.000  Activity biblical a disrupt of Nova Scotia rel...   \n",
       "1356       1852.000               After that cry there was a deep sigh   \n",
       "1357       1064.000  For those with understandable motives must bac...   \n",
       "1358       1101.000  Stress increases bungalow wall and respiration...   \n",
       "1359       2913.000            He was dogged in his pursuit of justice   \n",
       "\n",
       "                                              sentence1  \\\n",
       "0                I can not long conceal my dreadful sin   \n",
       "1              And that consists of a number of factors   \n",
       "2       Dad of a stagnant fermentation shrimp of doubts   \n",
       "3     Brisbane corp distant and finished commandos c...   \n",
       "4         Hours into cults cables help arrive in mounts   \n",
       "...                                                 ...   \n",
       "1355  Activity biblical a disrupt of Nova Scotia rel...   \n",
       "1356               After that cry there was a deep sigh   \n",
       "1357  Author of Causeway inactivity notation and exc...   \n",
       "1358  Oslo slammed prerequisite unequal questioned q...   \n",
       "1359            He was dogged in his pursuit of justice   \n",
       "\n",
       "                                              sentence2     source  \\\n",
       "0     What public schools teach their students is co...   internet   \n",
       "1            Birmingham but the heavy duty cell one and  generator   \n",
       "2     Mel causal that foothold overflowed paid Cpl a...  generator   \n",
       "3     The frustrating and bananas and the modificati...  generator   \n",
       "4     Listening those studied bails heater understan...  generator   \n",
       "...                                                 ...        ...   \n",
       "1355  Raven toned benched homeowners boiler and hurr...  generator   \n",
       "1356        Be guarded in executing your ideas of right   internet   \n",
       "1357  For those with understandable motives must bac...  generator   \n",
       "1358  Stress increases bungalow wall and respiration...  generator   \n",
       "1359  The vet arranged the busted inhaled harbour de...  generator   \n",
       "\n",
       "     sentence1_model_name sentence2_model_name  sentence1_model_level  \\\n",
       "0                     xlm                  xlm                      1   \n",
       "1                 electra              electra                      9   \n",
       "2                  bilstm               bilstm                      5   \n",
       "3                  bigram               bigram                      2   \n",
       "4                    lstm                 lstm                      5   \n",
       "...                   ...                  ...                    ...   \n",
       "1355      bert_whole_word      bert_whole_word                      4   \n",
       "1356                 lstm                 lstm                      3   \n",
       "1357                 gpt2                 gpt2                      4   \n",
       "1358                 bert                 bert                      0   \n",
       "1359                 gpt2                 gpt2                      9   \n",
       "\n",
       "      sentence2_model_level  Choice  \\\n",
       "0                         0     1.0   \n",
       "1                         5     0.0   \n",
       "2                         0     0.0   \n",
       "3                         6     0.0   \n",
       "4                         2     1.0   \n",
       "...                     ...     ...   \n",
       "1355                      2     0.0   \n",
       "1356                      0     0.0   \n",
       "1357                      7     1.0   \n",
       "1358                      3     1.0   \n",
       "1359                      2     0.0   \n",
       "\n",
       "                                       sentence_pair_id  \n",
       "0     I can not long conceal my dreadful sin_What pu...  \n",
       "1     And that consists of a number of factors_Birmi...  \n",
       "2     Dad of a stagnant fermentation shrimp of doubt...  \n",
       "3     Brisbane corp distant and finished commandos c...  \n",
       "4     Hours into cults cables help arrive in mounts_...  \n",
       "...                                                 ...  \n",
       "1355  Activity biblical a disrupt of Nova Scotia rel...  \n",
       "1356  After that cry there was a deep sigh_Be guarde...  \n",
       "1357  Author of Causeway inactivity notation and exc...  \n",
       "1358  Oslo slammed prerequisite unequal questioned q...  \n",
       "1359  He was dogged in his pursuit of justice_The ve...  \n",
       "\n",
       "[1360 rows x 15 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate negative log-likelihood of choice predictions given as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NLL(subject_data,predictions,mode='sum',deal_with_missing_predictions='omit',return_non_agg_NLL=False):\n",
    "    if 'subject' in predictions.columns: # predictions are subject-specific        \n",
    "        df=subject_data.merge(predictions,how='left',on=['sentence_pair_id','subject'])\n",
    "    else: # same predictions for all subjects\n",
    "        df=subject_data.merge(predictions,how='left',on=['sentence_pair_id'])\n",
    "    c=np.asarray(subject_data.Choice,dtype=float)\n",
    "    df['p']=np.where(c==0,df.choice_0_prob,df.choice_1_prob)    \n",
    "    df['p']=np.where(np.isnan(c),np.nan,df['p'])\n",
    "    \n",
    "    # deal with trials for which we have no predictions:\n",
    "    missing_predictions=np.logical_and(df['p'].isna(),np.logical_not(np.isnan(c))) # there's no prediction but the subject made a choice\n",
    "    \n",
    "    if np.any(missing_predictions):\n",
    "        print('Found {} missing predictions. Handling strategy: {}.'.format(np.sum(missing_predictions),deal_with_missing_predictions))\n",
    "        if deal_with_missing_predictions=='omit':\n",
    "            df=df.loc[np.logical_not(missing_predictions),:] # drop these trails\n",
    "        elif deal_with_missing_predictions=='uniform predictions':\n",
    "            df[missing_predictions,'p']=0.5 # make a uniform prediction\n",
    "        else:\n",
    "            raise ValueError(\"invalid deal_with_missing_predictions\")\n",
    "    \n",
    "    # calculate NLL\n",
    "    df['NLL']=-np.log(df['p'])\n",
    "    if mode=='sum':\n",
    "        agg_NLL=df.NLL.sum().item()        \n",
    "    elif mode=='mean':\n",
    "        agg_NLL=df.NLL.mean().item()\n",
    "    if return_non_agg_NLL:\n",
    "        return agg_NLL, df\n",
    "    else:\n",
    "        return agg_NLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper and lower bounds on the noise ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper noise ceiling NLL 448.9342475934038\n"
     ]
    }
   ],
   "source": [
    "def get_ub_noise_ceiling_predictions(subject_data):    \n",
    "    # calculate human choice probability per sentence (collapsed over subjects and within-subject repetitions)\n",
    "    df=subject_data.copy()\n",
    "    df['chose_0']=np.asarray(subject_data.Choice==0,np.float)\n",
    "    df['chose_0'].loc[np.isnan(subject_data.Choice)]==np.nan\n",
    "    df2=df.groupby('sentence_pair_id')['chose_0'].mean()\n",
    "    df2=df2.drop(columns=['subject']).reset_index().rename(columns={'chose_0':'choice_0_prob'})\n",
    "    df2['choice_1_prob']=1.0-np.asarray(df2.choice_0_prob)\n",
    "    return df2\n",
    "ub_NC_predictions=get_ub_noise_ceiling_predictions(protocol)\n",
    "\n",
    "def get_lb_noise_ceiling_predictions(subject_data):\n",
    "    # calculate leave-one-subject out human choice probability per sentence (collapsed over subjects and within-subject repetitions)\n",
    "    subjects=list(np.unique(subject_data.subject))\n",
    "    df1=subject_data.copy()\n",
    "    df1['chose_0']=np.asarray(df1.Choice==0,np.float)\n",
    "    df1['chose_0'].loc[np.isnan(df1.Choice)]==np.nan\n",
    "    \n",
    "    subject_specific_predictions_dfs=[]\n",
    "    for subject in subjects: # leave one-subject out cross-validation:\n",
    "        without_subject_df=df1.copy().loc[df1.subject!=subject,:] # hold out one subject            \n",
    "        subject_specific_predictions=without_subject_df.groupby('sentence_pair_id')['chose_0'].mean() # mean choice probabilities of the remaining subjects        \n",
    "        subject_specific_predictions=subject_specific_predictions.reset_index().rename(columns={'chose_0':'choice_0_prob'})\n",
    "        subject_specific_predictions['choice_1_prob']=1.0-np.asarray(subject_specific_predictions.choice_0_prob)                \n",
    "        subject_specific_predictions.loc[:,'subject']=subject # we mark the resulting predictions as subject-specific predictions\n",
    "        \n",
    "        # next, we remove predictions for sentence pairs the subject didn't see:\n",
    "        cur_subject_df=df1.copy().loc[df1.subject==subject,:] \n",
    "        cur_subject_sentence_pair_ids=np.unique(cur_subject_df.sentence_pair_id) # these are the sentences the subject saw\n",
    "        subject_specific_predictions=subject_specific_predictions.loc[np.in1d(subject_specific_predictions.sentence_pair_id,cur_subject_sentence_pair_ids),:]                \n",
    "        subject_specific_predictions_dfs.append(subject_specific_predictions) # and add the remaining predictions to the list\n",
    "    \n",
    "    lb_NC_predictions=pd.concat(subject_specific_predictions_dfs)\n",
    "    \n",
    "    return lb_NC_predictions\n",
    "lb_NC_predictions=get_lb_noise_ceiling_predictions(protocol)\n",
    "    \n",
    "ub_NC_NLL=evaluate_NLL(protocol,ub_NC_predictions,mode='sum')\n",
    "print(\"upper noise ceiling NLL\",ub_NC_NLL)\n",
    "\n",
    "# # without a Gamma parameter, the lower noise ceiling can be infinity\n",
    "# lb_NC_NLL,df=evaluate_NLL(protocol,lb_NC_predictions,mode='sum',return_non_agg_NLL=True)\n",
    "# print(\"lower noise ceiling NLL\",lb_NC_NLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Original fitsets generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_stim=pd.read_excel('contstim_pilot_n11_spreadsheet.xlsx')\n",
    "# task_data=pd.read_csv(task_data_csv)\n",
    "\n",
    "# models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2']\n",
    "\n",
    "# prob_dict=dict()\n",
    "# for model_name in [m for m in models if m != \"human_probs\"]:\n",
    "#     f = open(model_name+'_expt1_sentence_probs.pkl','rb')\n",
    "#     dict1=pickle.load(f)\n",
    "#     prob_dict[model_name]=dict1\n",
    "    \n",
    "    \n",
    "# events=list(task_data['Event Index'])\n",
    "# start_inds=[i for i,e in enumerate(events) if e=='1']\n",
    "\n",
    "# fitsets=[]\n",
    "\n",
    "# all_sents=[]\n",
    "\n",
    "# item_responses=dict()\n",
    "\n",
    "# for i,start_ind in enumerate(start_inds):\n",
    "\n",
    "#     setnum=task_data['counterbalance-o1ql'][start_ind]\n",
    "\n",
    "#     if i==12:\n",
    "#         setnum='set 12'\n",
    "\n",
    "#     sub=task_data['Participant External Session ID'][start_ind]\n",
    "\n",
    "#     model1_list=list(task_stim['sentence1_model_'+setnum])[1:]\n",
    "#     model2_list=list(task_stim['sentence2_model_'+setnum])[1:]\n",
    "#     sent1_list=list(task_stim['sentence1_'+setnum])[1:]\n",
    "#     sent2_list=list(task_stim['sentence2_'+setnum])[1:]\n",
    "\n",
    "#     if setnum=='set 1':\n",
    "#         source_list=list(task_stim['source'])[1:]\n",
    "\n",
    "#     else:\n",
    "#         source_list=list(task_stim['source_'+setnum])[1:]\n",
    "\n",
    "#     if i<len(start_inds)-1:\n",
    "#         responses_list=list(task_data['Response'][start_ind:start_inds[i+1]])\n",
    "\n",
    "#     else:\n",
    "#         responses_list=list(task_data['Response'][start_ind:])\n",
    "\n",
    "#     responses_list=[r for r in responses_list if str(r)!='nan']\n",
    "\n",
    "#     item_ids=[]\n",
    "\n",
    "#     fitset=[]\n",
    "    \n",
    "#     for t in range(110):\n",
    "\n",
    "#         source=source_list[t]\n",
    "\n",
    "#         model1=model1_list[t]\n",
    "#         model2=model2_list[t]\n",
    "#         sent1=sent1_list[t]\n",
    "#         sent2=sent2_list[t]\n",
    "        \n",
    "#         all_sents.append(sent1)\n",
    "#         all_sents.append(sent2)\n",
    "\n",
    "#         model1_name=model1[:-2]\n",
    "#         model2_name=model2[:-2]        \n",
    "\n",
    "#         model_ind=models.index(model1_name)\n",
    "\n",
    "#         sents=[sent1,sent2]\n",
    "#         sents_unsort=[sent1,sent2]     \n",
    "#         sents.sort()\n",
    "#         item_id='_'.join(sents)\n",
    "        \n",
    "#         response=responses_list[t]\n",
    "        \n",
    "#         if item_id in item_ids:\n",
    "#             continue\n",
    "            \n",
    "#         if item_id not in item_responses:\n",
    "#             item_responses[item_id]=[sents_unsort.index(response)]\n",
    "#         else:\n",
    "#             item_responses[item_id].append(sents_unsort.index(response))\n",
    "        \n",
    "#         item_ids.append(item_id)\n",
    "\n",
    "#         response_ind=[sent1,sent2].index(response)     \n",
    "        \n",
    "#         for model_name in models[:11]:#[model1_name]\n",
    "\n",
    "#             log_p1=prob_dict[model_name][sent1]\n",
    "#             log_p2=prob_dict[model_name][sent2]\n",
    "\n",
    "#             fitset.append([model_name,log_p1,log_p2,response_ind])\n",
    "            \n",
    "#         #log_human_p1=item_prob_ceilings[item_id][0]\n",
    "#         #log_human_p2=item_prob_ceilings[item_id][1]\n",
    "        \n",
    "#         #fitset.append(['human_probs',log_human_p1,log_human_p2,response_ind])\n",
    "        \n",
    "#     fitsets.append(fitset)\n",
    "\n",
    "# fitsets_all=[]\n",
    "# for fitset in fitsets:\n",
    "#     fitsets_all+=fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_sentence_probs(p_choice_1,p_choice_2,pseudo_sentence_prob_gamma=1.234,eps=1e-8):\n",
    "    p_choice_1=np.clip(p_choice_1,eps,1-eps)\n",
    "    p_choice_2=np.clip(p_choice_2,eps,1-eps)\n",
    "    \n",
    "    s1a_b=-np.log((1-p_choice_1)/p_choice_1)*pseudo_sentence_prob_gamma  \n",
    "    lp1=-100+s1a_b/2\n",
    "    lp2=-100-s1a_b/2\n",
    "\n",
    "    return lp1,lp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised fitsets generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2','ub_NC','lb_NC']\n",
    "\n",
    "comp_models=list(np.setdiff1d(models,['ub_NC','lb_NC']))\n",
    "human_models=list(np.setdiff1d(models,comp_models))\n",
    "\n",
    "prob_dict=dict()\n",
    "for model_name in comp_models:\n",
    "    f = open(model_name+'_expt1_sentence_probs.pkl','rb')\n",
    "    prob_dict[model_name]=pickle.load(f)\n",
    "\n",
    "fitsets=[]\n",
    "for i_subject in range(n_subjects):\n",
    "    cur_sub_protocol=protocol.loc[protocol.subject==i_subject,:]\n",
    "    \n",
    "    fitset=[]\n",
    "    for i_trial, trial in cur_sub_protocol.iterrows():\n",
    "        for model_name in models:\n",
    "            if model_name in comp_models:\n",
    "                log_p1=prob_dict[model_name][trial.sentence1]\n",
    "                log_p2=prob_dict[model_name][trial.sentence2]\n",
    "                fitset.append([model_name,log_p1,log_p2,trial.Choice])\n",
    "            if model_name in human_models:\n",
    "                # get predictions from dataframe \n",
    "                predictions_df={'ub_NC':ub_NC_predictions,'lb_NC':lb_NC_predictions}[model_name]                \n",
    "                if 'subject' in predictions_df.columns: # deal with subject-specific predictions\n",
    "                    filter_vars=['sentence_pair_id','subject']\n",
    "                else:\n",
    "                    filter_vars=['sentence_pair_id']\n",
    "                    \n",
    "                cur_prediction=trial.to_frame().T.merge(predictions_df,how='left',on=filter_vars)\n",
    "                assert len(cur_prediction)==1, 'exactly one prediction should be provided for each trial (found {} for subject {}: {}).'.format(len(cur_prediction),trial.subject,trial.sentence_pair_id)\n",
    "                                    \n",
    "                p1=cur_prediction.loc[0,'choice_0_prob']\n",
    "                p2=cur_prediction.loc[0,'choice_1_prob']\n",
    "                \n",
    "                assert np.isfinite(p1) and np.isfinite(p2), 'found nan predictions for subject {}: {}).'.format(trial.subject,trial.sentence_pair_id)\n",
    "                \n",
    "                log_p1,log_p2=pseudo_sentence_probs(p1,p2)\n",
    "                fitset.append([model_name,log_p1,log_p2,trial.Choice])\n",
    "            \n",
    "    fitsets.append(fitset)\n",
    "\n",
    "fitsets_all=[]\n",
    "for fitset in fitsets:\n",
    "    fitsets_all+=fitset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "minps=[]\n",
    "for m in models:\n",
    "    m=np.min([np.min([trial[1],trial[2]]) for trial in fitsets_all if trial[0]==m])\n",
    "    minps.append(m)\n",
    "    \n",
    "minps=np.abs(minps)\n",
    "\n",
    "\n",
    "maxps=[]\n",
    "for m in models:\n",
    "    m=np.max([np.max([trial[1],trial[2]]) for trial in fitsets_all if trial[0]==m])\n",
    "    maxps.append(m)\n",
    "    \n",
    "maxps=np.abs(maxps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overflow within exponentials when calculating probabilities, we'll use torch.logsumexp where log(exp(x)+1) is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(1+exp(x)) | direct implementation: tensor([ 0.0000, 50.0000,  0.3133,  0.6931,  1.3133, 50.0000,     inf])\n",
      "log(1+exp(x)) | with logsumexp: tensor([  0.0000,  50.0000,   0.3133,   0.6931,   1.3133,  50.0000, 100.0000])\n",
      "log(1/(1+exp(x))) | direct implementation: tensor([  0.0000, -50.0000,  -0.3133,  -0.6931,  -1.3133, -50.0000,     -inf])\n",
      "log(1/(1+exp(x))) | with logsumexp: tensor([  -0.0000,  -50.0000,   -0.3133,   -0.6931,   -1.3133,  -50.0000,\n",
      "        -100.0000])\n",
      "log(1 - 1/(1+exp(x))) | direct implementation: tensor([   -inf,  0.0000, -1.3133, -0.6931, -0.3133,  0.0000,  0.0000])\n",
      "log(1 - 1/(1+exp(x))) | with logsumexp: tensor([-100.0000,    0.0000,   -1.3133,   -0.6931,   -0.3133,    0.0000,\n",
      "           0.0000])\n"
     ]
    }
   ],
   "source": [
    "# this is mathemathically eqivalent to torch.log(1+torch.exp(x)) but it doesn't overflow when x is big.\n",
    "log_1_plus_exp_x=lambda x: torch.logsumexp(torch.stack((x,torch.zeros_like(x)),dim=-1),dim=1)\n",
    "\n",
    "# this is mathemathically equivalent to log(1/(1+exp(x)))\n",
    "log_p=lambda x: -log_1_plus_exp_x(x) \n",
    "\n",
    "# this is mathemathically equivalent to log(1 - 1/(1+exp(x)) )\n",
    "log_1_minus_p=lambda x: x+log_p(x)\n",
    "\n",
    "x=torch.tensor([-100.0,50.0,-1.0,0.0,1.0,50.0,100.0])\n",
    "print('log(1+exp(x)) | direct implementation:', torch.log(1+torch.exp(x)))\n",
    "print('log(1+exp(x)) | with logsumexp:', log_1_plus_exp_x(x))\n",
    "\n",
    "print('log(1/(1+exp(x))) | direct implementation:', torch.log(1/(1+torch.exp(x))))\n",
    "print('log(1/(1+exp(x))) | with logsumexp:', log_p(x))\n",
    "\n",
    "print('log(1 - 1/(1+exp(x))) | direct implementation:', torch.log(1-1/(1+torch.exp(x))))\n",
    "print('log(1 - 1/(1+exp(x))) | with logsumexp:', log_1_minus_p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelToHumanDecision():\n",
    "    def _set_initial_parameters(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __init__(self,model_name_list,parameters=None,device=None):\n",
    "        if device is None:\n",
    "            device='cpu'\n",
    "        \n",
    "        self.device=torch.device(device)\n",
    "        self.model_name_list=model_name_list\n",
    "        self.n_models=len(model_name_list)\n",
    "        \n",
    "        if parameters is None:\n",
    "            self.parameters=self._initial_parameters()\n",
    "        else:\n",
    "            self.parameters={key:torch.tensor(value,device=self.device,dtype=torch.float64) for (key,value) in parameters.items()}\n",
    "\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def decision_NLL(self,log_p1,log_p2,model=None):\n",
    "        \n",
    "        log_p1=torch.as_tensor(log_p1,device=self.device,dtype=torch.float64)\n",
    "        log_p2=torch.as_tensor(log_p2,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        if model is None: # evaluate all models. # log_p1, log_p2 (n_models,n_sentence_pairs)\n",
    "            assert log_p1.ndim==2 and log_p1.shape[0]==self.n_models and log_p2.ndim==3 and log_p2.shape[0]==self.n_models \n",
    "            slicer=...\n",
    "        elif type(model) is str: # one particular model specified by its name\n",
    "            slicer=self.model_name_list.index(model)\n",
    "        elif type(model) is int: # one particular model specified by its index\n",
    "            slicer=model\n",
    "        elif type(model) is list: # a list of model names\n",
    "            slicer=torch.tensor([self.model_name_list.index(m) for m in model])\n",
    "        else:\n",
    "            raise \n",
    "        cur_parameters={}\n",
    "        \n",
    "#         print(self.parameters.items())\n",
    "#         sys.e\n",
    "        \n",
    "        for par_name, par in self.parameters.items():\n",
    "            if par.nelement()==1:\n",
    "                cur_parameters[par_name]=par\n",
    "            else:\n",
    "                cur_parameters[par_name]=par[slicer]\n",
    "        return self._f(log_p1,log_p2,cur_parameters)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        numpy_parameters={}\n",
    "        for par_name, par in self.parameters.items():\n",
    "            if par.nelement()==1:\n",
    "                numpy_parameters[par_name]=par.item()\n",
    "            else:\n",
    "                numpy_parameters[par_name]=par.detach().cpu().numpy()\n",
    "        return numpy_parameters\n",
    "\n",
    "class FixedWidthSquashing(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.tensor(10.0,device=self.device)\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=1.0\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))        \n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL\n",
    "\n",
    "    \n",
    "class FixedWidthSquashingVariableGamma(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        return parameters\n",
    "    \n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=1.0\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "        #log_p1_corrected=width*torch.log(1+math.e**((log_p1+squash_threshold)/width))-squash_threshold\n",
    "        #log_p2_corrected=width*torch.log(1+math.e**((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL\n",
    "\n",
    "class VariableWidthSquashing(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.tensor(10.0,device=self.device)\n",
    "        parameters['width']=torch.ones(self.n_models,device=self.device)        \n",
    "        return parameters\n",
    "    \n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=torch.nn.Softplus()(cur_parameters['width'])+1e-1\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "#         log_p1_corrected=width*torch.log(1+torch.exp((log_p1+squash_threshold)/width))-squash_threshold\n",
    "#         log_p2_corrected=width*torch.log(1+torch.exp((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "\n",
    "\n",
    "class VariableWidthSquashingVariableGamma(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        parameters['width']=torch.ones(self.n_models,device=self.device)\n",
    "\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=torch.nn.Softplus()(cur_parameters['width'])+1e-1\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "#         log_p1_corrected=width*torch.log(1+math.e**((log_p1+squash_threshold)/width))-squash_threshold\n",
    "#         log_p2_corrected=width*torch.log(1+math.e**((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "    \n",
    "\n",
    "class VariableGammaNoSquash(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        s1a_b = log_p1 - log_p2\n",
    "        p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "        p2=1-p1\n",
    "        choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "    \n",
    "class SquashedSoftmax(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        parameters['eta']=torch.ones(self.n_models,device=self.device)*(0.0)\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        eta=cur_parameters['eta']\n",
    "        \n",
    "        denominator=torch.logsumexp(torch.stack([log_p1/gamma,torch.ones_like(log_p1)*eta,log_p2/gamma,torch.ones_like(log_p2)*eta],dim=-1),dim=-1)\n",
    "        log_p1 = torch.logsumexp(torch.stack([log_p1/gamma,torch.ones_like(log_p1)*eta],dim=-1),dim=-1)-denominator\n",
    "        log_p2 = torch.logsumexp(torch.stack([log_p2/gamma,torch.ones_like(log_p2)*eta],dim=-1),dim=-1)-denominator\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "loss: tensor(15805.4551, grad_fn=<AddBackward0>)\n",
      "squashes tensor([172.6353, 158.2039, 186.6036, 191.4571, 141.2743, 151.7397, 150.0234,\n",
      "        151.1320, 147.1514, 134.0681, 128.9228, 109.2103, 109.2103],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "\n",
      "loss: tensor(10678.4824, grad_fn=<AddBackward0>)\n",
      "squashes tensor([150.0433, 137.7758, 201.7364,  96.1794,  92.9834,  98.0875,  94.5237,\n",
      "        102.9982,  92.9373,  87.3163,  92.8379, 118.5655,  99.0283],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([26.9722, 28.4507, 39.3416, 36.6912, 31.0461, 31.2030, 32.6398, 30.8055,\n",
      "        32.1385, 30.9666, 31.0162,  1.0156, 22.6528], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10668.1104, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.2775, 138.7478, 202.0441,  96.8171,  89.8468,  97.3347,  93.4408,\n",
      "        100.6508,  92.9014,  85.5253,  93.4667, 118.5669,  99.1829],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.9884, 28.9694, 45.8873, 35.3458, 29.2019, 29.7162, 32.0819, 28.9064,\n",
      "        31.3232, 29.4010, 31.2980,  1.0000, 22.6418], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10664.6621, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1216, 139.0466, 202.3850,  95.6948,  88.2472,  93.3898,  92.6092,\n",
      "         99.6426,  92.3926,  84.5985,  93.9551, 118.5669,  99.1887],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7994, 29.2049, 49.6339, 33.8875, 27.3453, 27.6808, 31.4938, 27.6394,\n",
      "        30.7550, 28.2785, 31.5541,  1.0000, 22.6578], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10663.3379, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1114, 139.1486, 202.7008,  94.8704,  87.7769,  90.4957,  91.6423,\n",
      "         99.3408,  92.1317,  84.3249,  94.6731, 118.5669,  99.1959],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7873, 29.2843, 51.9144, 32.7967, 26.6902, 25.2467, 30.8729, 27.2502,\n",
      "        30.4744, 27.9208, 31.8491,  1.0000, 22.6771], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.8799, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1747, 202.9797,  94.3564,  87.7042,  89.1199,  90.8189,\n",
      "         99.2900,  92.0324,  84.2773,  97.8720, 118.5669,  99.2043],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3046, 53.3137, 32.1527, 26.5876, 23.9958, 30.2756, 27.1848,\n",
      "        30.3688, 27.8584, 32.5661,  1.0000, 22.6996], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.5859, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1796, 203.2245,  94.0912,  87.6981,  88.8287,  90.3052,\n",
      "         99.2849,  92.0031,  84.2722, 100.6087, 118.5669,  99.2137],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3084, 54.1565, 31.8361, 26.5790, 23.7177, 29.8597, 27.1782,\n",
      "        30.3378, 27.8518, 34.2993,  1.0000, 22.7251], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.5586, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 203.4405,  93.9759,  87.6979,  88.7951,  90.0493,\n",
      "         99.2846,  91.9963,  84.2719, 100.7800, 118.5669,  99.2243],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3089, 54.6460, 31.7022, 26.5786, 23.6856, 29.6436, 27.1778,\n",
      "        30.3305, 27.8514, 34.5349,  1.0000, 22.7535], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.5518, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 203.6332,  93.9328,  87.6979,  88.7927,  89.9428,\n",
      "         99.2846,  91.9950,  84.2719, 100.7908, 118.5669,  99.2360],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 54.9170, 31.6527, 26.5786, 23.6833, 29.5524, 27.1778,\n",
      "        30.3292, 27.8514, 34.5502,  1.0000, 22.7849], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.5508, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 203.8066,  93.9188,  87.6979,  88.7926,  89.9047,\n",
      "         99.2846,  91.9948,  84.2719, 100.7912, 118.5669,  99.2487],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 55.0586, 31.6368, 26.5786, 23.6832, 29.5197, 27.1778,\n",
      "        30.3290, 27.8514, 34.5508,  1.0000, 22.8192], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.5498, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 203.9643,  93.9149,  87.6979,  88.7926,  89.8929,\n",
      "         99.2846,  91.9948,  84.2719, 100.7913, 118.5669,  99.2626],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 55.1279, 31.6322, 26.5786, 23.6832, 29.5095, 27.1778,\n",
      "        30.3290, 27.8514, 34.5508,  1.0000, 22.8565], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(10662.5498, grad_fn=<AddBackward0>)\n",
      "squashes tensor([149.1112, 139.1803, 204.1088,  93.9139,  87.6979,  88.7926,  89.8896,\n",
      "         99.2846,  91.9948,  84.2719, 100.7913, 118.5669,  99.2775],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([25.7871, 29.3090, 55.1596, 31.6311, 26.5786, 23.6832, 29.5068, 27.1778,\n",
      "        30.3290, 27.8514, 34.5508,  1.0000, 22.8968], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "{'squashes': array([149.11119465, 139.18034908, 204.12419303,  93.91386671,\n",
      "        87.69785544,  88.7926001 ,  89.8894728 ,  99.2846165 ,\n",
      "        91.99481549,  84.27189394, 100.79125734, 118.56686421,\n",
      "        99.27925283]), 'gamma': array([25.7871429 , 29.30896009, 55.16175117, 31.63109201, 26.57863977,\n",
      "       23.6832158 , 29.50663311, 27.17782044, 30.32898546, 27.85135288,\n",
      "       34.55084805,  0.99999597, 22.9014773 ])}\n",
      "total loss: tensor(10662.5498, grad_fn=<AddBackward0>)\n",
      "bigram 842.35\n",
      "trigram 844.61\n",
      "rnn 855.28\n",
      "lstm 840.58\n",
      "bilstm 842.33\n",
      "bert 845.38\n",
      "bert_whole_word 848.27\n",
      "roberta 841.22\n",
      "xlm 845.99\n",
      "electra 842.59\n",
      "gpt2 841.96\n",
      "ub_NC 448.93\n",
      "lb_NC 923.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':10.0}\n",
    "# model_class=FixedWidthSquashing\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':10.0,'width':np.ones(len(models))}\n",
    "# model_class=VariableWidthSquashing\n",
    "\n",
    "parameters={'squashes':minps,'gamma':np.ones_like(minps)*10.0}\n",
    "model_class=FixedWidthSquashingVariableGamma\n",
    "\n",
    "# parameters={'gamma':np.ones_like(minps)*10.0}\n",
    "# model_class=VariableGammaNoSquash\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':np.ones_like(minps)*10.0,'width':np.ones(len(models))}\n",
    "# model_class=VariableWidthSquashingVariableGamma\n",
    "\n",
    "# parameters=None # use defaults\n",
    "# model_class=SquashedSoftmax\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "for boot in range(1):\n",
    "    \n",
    "#     boots=np.random.choice(13, 13)\n",
    "    boots=np.arange(13)\n",
    "    \n",
    "    fitset=[]\n",
    "    for b in boots:\n",
    "        fitset+=fitsets[b]\n",
    "    \n",
    "    decision_model=model_class(model_name_list=models,parameters=parameters,device=device)\n",
    "\n",
    "    for par in decision_model.parameters.values():\n",
    "        par.requires_grad=True\n",
    "        \n",
    "    opt = optim.Adam(decision_model.parameters.values(),lr=1)\n",
    "\n",
    "    print(boot)\n",
    "    print('')\n",
    "\n",
    "    # build models by trials by sentences log-prob matrix\n",
    "    \n",
    "    log_p1=defaultdict(list)\n",
    "    log_p2=defaultdict(list)\n",
    "    response_ind=defaultdict(list)\n",
    "    \n",
    "    for trial in fitset:\n",
    "        model1_name=trial[0]\n",
    "        log_p1[model1_name].append(trial[1])\n",
    "        log_p2[model1_name].append(trial[2])\n",
    "        response_ind[model1_name].append(trial[3])\n",
    "        \n",
    "    \n",
    "    for epoch in range(1000): # for some models, one needs more than 200 epochs for convergence. I'd replace this loop with a convergence criterion.\n",
    "\n",
    "        loss = torch.tensor(0.,device=device,requires_grad = True)\n",
    "        \n",
    "        model_loss=torch.zeros((len(models)),device=device)\n",
    "        \n",
    "        for i_model,model1_name in enumerate(models):\n",
    "            log_p_sent=decision_model.decision_NLL(log_p1[model1_name],log_p2[model1_name],model=model1_name)\n",
    "            take_by_2nd_dim=lambda x, idx: x[torch.arange(x.size(0)), idx] \n",
    "            log_p_choice=take_by_2nd_dim(log_p_sent,response_ind[model1_name])\n",
    "            model_loss[i_model]=log_p_choice.sum()\n",
    "            loss=loss+model_loss[i_model]\n",
    "            \n",
    "        if epoch%90==0:\n",
    "            print('loss:',loss)\n",
    "            for par_name, par in decision_model.parameters.items():\n",
    "                print(par_name,par)\n",
    "            print('')\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    print(decision_model.get_parameters())\n",
    "    print('total loss:',loss)\n",
    "    for i_model,model1_name in enumerate(models):\n",
    "        print('{} {:.2f}'.format(model1_name,model_loss[i_model].item()))\n",
    "        \n",
    "    squashes=list(decision_model.parameters['squashes'].data.numpy())\n",
    "    gammas=list(decision_model.parameters['gamma'].data.numpy())\n",
    "    #gammas=float(decision_model.parameters['gamma'])\n",
    "    \n",
    "    if boot==0:\n",
    "        squash_boots=[squashes]\n",
    "        gamma_boots=[gammas]\n",
    "        losses=[m.item() for m in model_loss]\n",
    "    else:\n",
    "        squash_boots.append(squashes)\n",
    "        gamma_boots.append(gammas)\n",
    "        losses.append([m.item() for m in model_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/numpy/lib/function_base.py:2551: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/numpy/lib/function_base.py:2480: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/numpy/lib/function_base.py:2480: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gT=np.array(gamma_boots).T\n",
    "sT=np.array(squash_boots).T\n",
    "\n",
    "ccs=[]\n",
    "for i in range(11):\n",
    "    \n",
    "    cc=np.corrcoef(sT[i,:],gT[i,:])[0,1]\n",
    "    ccs.append(cc)\n",
    "    \n",
    "ccs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synthetic\n",
    "\n",
    "# tensor(671.4779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([129.5626, 128.7844,  84.1193,  92.4041, 111.8108, 105.3416,  83.8154,\n",
    "#         116.5818,  87.0363,  60.6492,  81.0560], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([29.8585, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n",
    "\n",
    "\n",
    "#natural\n",
    "\n",
    "# tensor(148.7837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([115.8415,  84.2844,  72.0876,  43.8699,  54.9998,  50.4821,  69.6983,\n",
    "#          49.1065,  42.4528,  34.6840,  59.5816], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([ 9.1418, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n",
    "\n",
    "\n",
    "# tensor(829.6835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([129.1968, 127.7177,  83.4297,  91.0015, 111.4391, 104.3089,  83.3092,\n",
    "#         115.3282,  85.6379,  59.8025,  79.7266], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([28.2664, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squash_boots=np.array([[136.6031, 130.6315,  88.2857, 127.1014, 124.6718, 110.4878,  84.6417,\n",
    "#         118.1435, 107.7737,  63.0790,  79.9143],\n",
    "#               [137.9003, 125.7105,  84.5635, 127.1772, 112.0871,  94.5774,  78.6344,\n",
    "#         114.0863,  95.4273,  58.2541,  79.6323],\n",
    "#               [131.8761, 133.7181, 147.7142, 143.2530, 110.6293, 134.2203,  83.7578,\n",
    "#         139.0220,  82.7407,  66.7261,  79.2919],\n",
    "#               [139.6443, 135.6945,  80.5810,  94.8058, 116.6113, 103.0531,  87.4392,\n",
    "#         119.7775,  81.2322,  60.9193,  81.1773],\n",
    "#               [132.4967, 128.7608,  92.4549,  91.8489, 110.4346, 104.1544,  80.5317,\n",
    "#         126.0785, 124.9601,  57.4880,  76.9285],\n",
    "#               [128.2988, 112.9426,  80.0811,  90.9844, 111.0652, 115.8396,  56.3730,\n",
    "#          78.9889, 120.2621,  29.6331,  61.9582],\n",
    "#               [127.7181, 132.9688, 148.8201,  94.7272, 109.7225,  87.5404,  81.3132,\n",
    "#         115.8013, 116.9241,  64.7583,  73.5550],\n",
    "#               [120.8540, 116.8421, 135.4461,  88.5892, 124.1079, 133.7935,  86.1704,\n",
    "#         100.1683,  92.7386,  49.7565,  79.4477],\n",
    "#               [125.4391, 114.5180,  82.5459,  87.4416, 110.8198,  93.8739,  63.4568,\n",
    "#         117.9814,  83.9064,  57.2624,  77.2107],\n",
    "#               [129.6447, 129.3590,  86.6444,  92.5276, 109.5141, 105.0256,  65.8152,\n",
    "#         117.5682, 125.8277,  59.4612,  77.8789]])\n",
    "\n",
    "s=squash_boots\n",
    "\n",
    "squash_boots=np.array(losses).T\n",
    "squash_boots.sort()\n",
    "squash_boots=squash_boots.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squash_boots=squash_boots.reshape([10,11])\n",
    "\n",
    "\n",
    "\n",
    "x=np.arange(11)*2\n",
    "# plt.bar(x-0.2, maxps, width=0.1, color=[1,0,0])\n",
    "plt.bar(x-0.1, squash_boots[0], width=0.1, color=[0,0,1])\n",
    "plt.bar(x, squash_boots[1], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.1, squash_boots[2], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.2, squash_boots[3], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.3, squash_boots[4], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.4, squash_boots[5], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.5, squash_boots[6], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.6, squash_boots[7], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.7, squash_boots[8], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.8, squash_boots[9], width=0.1, color=[0,0,1])\n",
    "# plt.bar(x+0.9, minps, width=0.1, color=[1,0,0])\n",
    "\n",
    "# plt.ylabel('Squash Thresholds')\n",
    "plt.ylabel('Negative log likelihood')\n",
    "plt.xticks(x,models,rotation=70)\n",
    "\n",
    "# plt.ylim([800,950])\n",
    "\n",
    "legs=['Min/Max baseline','Squash thresholds']\n",
    "# plt.legend(legs,bbox_to_anchor=(1, 0.3, 0.2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=squash_boots.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=np.array([f.sort() for f in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_boots=d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist=list(set(all_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('test_sents_expt1_first13subs.txt','w')\n",
    "for s in slist:\n",
    "    file.write(s)\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model.parameters['squashes'].data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sent1,sent2].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=0\n",
    "a=0\n",
    "for trial in fitset:\n",
    "    \n",
    "    if trial[0]=='electra':\n",
    "        \n",
    "        a+=1\n",
    "    \n",
    "        pa=trial[1]\n",
    "        pb=trial[2]\n",
    "        c=trial[3]\n",
    "\n",
    "        if c==0 and pa>pb:\n",
    "            g+=1\n",
    "        elif c==1 and pb>pa:\n",
    "            g+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g/len(fitset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(item_prob_ceilings[item_id][1])==-math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
