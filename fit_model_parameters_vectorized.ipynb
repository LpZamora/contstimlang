{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.dpi']= 200\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data_csv='data_exp1_cumulative.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 70 within-subject repeating trials.\n"
     ]
    }
   ],
   "source": [
    "def prepare_tidy_protocol(csv_path,do_remove_within_subject_repetitions=True):\n",
    "    df=pd.read_csv(csv_path)\n",
    "    \n",
    "    df=df.loc[df.Response.notna(),:] #drop non-response lines\n",
    "    df=df.rename(columns={'source':'source_set 1'}) # fix a mistake in model naming\n",
    "    df=df.rename(columns={'counterbalance-o1ql':'set_num'})\n",
    "\n",
    "    # transform set columns to trial columns\n",
    "    p = re.compile('(.+)_set \\d+')\n",
    "    set_columns=[s for s in list(df.columns) if p.match(s)]\n",
    "    columns_to_keep=['Participant External Session ID','Event Index','Reaction Time','Response','set_num']+set_columns\n",
    "    columns_to_drop=list(np.setdiff1d(df.columns,columns_to_keep))\n",
    "    df=df.drop(columns=columns_to_drop)\n",
    "    columns_to_build=list(np.unique([p.findall(s)[0] for s in set_columns]))\n",
    "    for index,row in df.iterrows():\n",
    "        cur_set=row['set_num']\n",
    "        for c in columns_to_build:\n",
    "            df.loc[index,c]=df.loc[index,c+'_'+cur_set]\n",
    "    df=df.drop(columns=set_columns+['set_num'])\n",
    "\n",
    "    # make sure the sentence pairs are alphabetically sorted\n",
    "    def sort_sentence_pairs(df1):    \n",
    "        flip_dict={'sentence1':'sentence2','sentence2':'sentence1',\n",
    "                   'sentence1_model':'sentence2_model','sentence2_model':'sentence1_model'}\n",
    "        df2=df1.copy()    \n",
    "        for index, row in df2.iterrows():\n",
    "            if row['sentence1']>row['sentence2']: # a flip is needed\n",
    "                for old_col, new_col in flip_dict.items():\n",
    "                    df2.loc[index,new_col]=df1.loc[index,old_col]\n",
    "        return df2\n",
    "    df=sort_sentence_pairs(df)\n",
    "\n",
    "    # separate models and levels\n",
    "    p=re.compile('(.+)_(\\d+)')\n",
    "    df['sentence1_model_name']=[p.findall(s)[0][0] for s in df['sentence1_model']]\n",
    "    df['sentence2_model_name']=[p.findall(s)[0][0] for s in df['sentence2_model']]\n",
    "    df['sentence1_model_level']=[int(p.findall(s)[0][1]) for s in df['sentence1_model']]\n",
    "    df['sentence2_model_level']=[int(p.findall(s)[0][1]) for s in df['sentence2_model']]\n",
    "    df=df.drop(columns=['sentence1_model','sentence2_model'])\n",
    "\n",
    "    # mark choice indecis\n",
    "    for index,row in df.iterrows():\n",
    "        df.loc[index,'Choice']=[row.sentence1, row.sentence2].index(row.Response)\n",
    "\n",
    "    df['sentence_pair_id']=[s1+'_'+s2 for s1,s2 in zip(df.sentence1, df.sentence2)]\n",
    "\n",
    "    # renumber subjects\n",
    "    df.drop(columns='subject') # there's some issue here    \n",
    "    uq_subjects, ind, unique_inverse = np.unique(df['Participant External Session ID'], return_index=True,return_inverse=True)\n",
    "    uq_subjects=list(uq_subjects[np.argsort(ind)]) # unique subjects by order of appearance    \n",
    "    df['subject']=[uq_subjects.index(s) for s in df['Participant External Session ID']]\n",
    "                   \n",
    "    # optionally, remove all but first occurance of each sentence pair within a subject    \n",
    "    if do_remove_within_subject_repetitions:\n",
    "        def remove_within_subject_repetitions(df1):\n",
    "            # keep only the first appearance of each sentence pair within a subject\n",
    "            _,unique_indices=np.unique(df1.sentence_pair_id,return_index=True)\n",
    "            df2=df1.loc[np.in1d(np.arange(len(df1)),unique_indices),:]    \n",
    "            return df2\n",
    "        old_length=len(df)\n",
    "        df=df.groupby('subject').apply(remove_within_subject_repetitions)\n",
    "        print(\"removed {} within-subject repeating trials.\".format(old_length-len(df)))\n",
    "        \n",
    "    df=df.set_index(['subject','trial']).sort_values(by=['subject','trial'],axis=0).reset_index()\n",
    "    return df\n",
    "protocol=prepare_tidy_protocol(task_data_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 2570 total trials with 605 sentence pairs and 24 subjects.\n"
     ]
    }
   ],
   "source": [
    "n_total_trials=len(protocol)\n",
    "n_sentence_pairs=len(np.unique(protocol['sentence_pair_id']))\n",
    "n_subjects=len(np.unique(protocol['Participant External Session ID']))\n",
    "print(\"loaded {} total trials with {} sentence pairs and {} subjects.\".format(n_total_trials,n_sentence_pairs,n_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>Event Index</th>\n",
       "      <th>Participant External Session ID</th>\n",
       "      <th>Reaction Time</th>\n",
       "      <th>Response</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence1_model_name</th>\n",
       "      <th>sentence2_model_name</th>\n",
       "      <th>sentence1_model_level</th>\n",
       "      <th>sentence2_model_level</th>\n",
       "      <th>Choice</th>\n",
       "      <th>sentence_pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>5812.220000</td>\n",
       "      <td>What public schools teach their students is co...</td>\n",
       "      <td>I can not long conceal my dreadful sin</td>\n",
       "      <td>What public schools teach their students is co...</td>\n",
       "      <td>internet</td>\n",
       "      <td>xlm</td>\n",
       "      <td>xlm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I can not long conceal my dreadful sin_What pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>And that consists of a number of factors</td>\n",
       "      <td>And that consists of a number of factors</td>\n",
       "      <td>Birmingham but the heavy duty cell one and</td>\n",
       "      <td>generator</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>And that consists of a number of factors_Birmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>9964.815000</td>\n",
       "      <td>Dad of a stagnant fermentation shrimp of doubts</td>\n",
       "      <td>Dad of a stagnant fermentation shrimp of doubts</td>\n",
       "      <td>Mel causal that foothold overflowed paid Cpl a...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dad of a stagnant fermentation shrimp of doubt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>11878.520000</td>\n",
       "      <td>Brisbane corp distant and finished commandos c...</td>\n",
       "      <td>Brisbane corp distant and finished commandos c...</td>\n",
       "      <td>The frustrating and bananas and the modificati...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bigram</td>\n",
       "      <td>bigram</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brisbane corp distant and finished commandos c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5f89a28900ebf4068239ad58</td>\n",
       "      <td>12686.870000</td>\n",
       "      <td>Listening those studied bails heater understan...</td>\n",
       "      <td>Hours into cults cables help arrive in mounts</td>\n",
       "      <td>Listening those studied bails heater understan...</td>\n",
       "      <td>generator</td>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hours into cults cables help arrive in mounts_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>214</td>\n",
       "      <td>5fde554b85dbbb5cf9a1d168</td>\n",
       "      <td>1467.500000</td>\n",
       "      <td>List of people in America who hate it</td>\n",
       "      <td>Blog negative blog shelve grammar represents c...</td>\n",
       "      <td>List of people in America who hate it</td>\n",
       "      <td>generator</td>\n",
       "      <td>xlm</td>\n",
       "      <td>xlm</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Blog negative blog shelve grammar represents c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>23</td>\n",
       "      <td>107.0</td>\n",
       "      <td>216</td>\n",
       "      <td>5fde554b85dbbb5cf9a1d168</td>\n",
       "      <td>2621.625001</td>\n",
       "      <td>Lions in his most charming little extraterrest...</td>\n",
       "      <td>Forces bucks hometown donors Berger complicati...</td>\n",
       "      <td>Lions in his most charming little extraterrest...</td>\n",
       "      <td>generator</td>\n",
       "      <td>trigram</td>\n",
       "      <td>trigram</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Forces bucks hometown donors Berger complicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>23</td>\n",
       "      <td>108.0</td>\n",
       "      <td>218</td>\n",
       "      <td>5fde554b85dbbb5cf9a1d168</td>\n",
       "      <td>2137.399999</td>\n",
       "      <td>Immediately after completing algorithms the ga...</td>\n",
       "      <td>Danny Louvre shrouded typically flees offendin...</td>\n",
       "      <td>Immediately after completing algorithms the ga...</td>\n",
       "      <td>generator</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Danny Louvre shrouded typically flees offendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>23</td>\n",
       "      <td>109.0</td>\n",
       "      <td>220</td>\n",
       "      <td>5fde554b85dbbb5cf9a1d168</td>\n",
       "      <td>1881.740000</td>\n",
       "      <td>The man sleeps with the second solid object</td>\n",
       "      <td>Hart bitter motions Toledo going whacking emer...</td>\n",
       "      <td>The man sleeps with the second solid object</td>\n",
       "      <td>generator</td>\n",
       "      <td>xlm</td>\n",
       "      <td>xlm</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hart bitter motions Toledo going whacking emer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>23</td>\n",
       "      <td>110.0</td>\n",
       "      <td>222</td>\n",
       "      <td>5fde554b85dbbb5cf9a1d168</td>\n",
       "      <td>2625.890001</td>\n",
       "      <td>Anyone electron elevation ponies circulate the...</td>\n",
       "      <td>Anyone electron elevation ponies circulate the...</td>\n",
       "      <td>Want sits preaching subscription as spotlights...</td>\n",
       "      <td>generator</td>\n",
       "      <td>bigram</td>\n",
       "      <td>bigram</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anyone electron elevation ponies circulate the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2570 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  trial Event Index Participant External Session ID  \\\n",
       "0           0    1.0           4        5f89a28900ebf4068239ad58   \n",
       "1           0    2.0           6        5f89a28900ebf4068239ad58   \n",
       "2           0    3.0           8        5f89a28900ebf4068239ad58   \n",
       "3           0    4.0          10        5f89a28900ebf4068239ad58   \n",
       "4           0    5.0          12        5f89a28900ebf4068239ad58   \n",
       "...       ...    ...         ...                             ...   \n",
       "2565       23  106.0         214        5fde554b85dbbb5cf9a1d168   \n",
       "2566       23  107.0         216        5fde554b85dbbb5cf9a1d168   \n",
       "2567       23  108.0         218        5fde554b85dbbb5cf9a1d168   \n",
       "2568       23  109.0         220        5fde554b85dbbb5cf9a1d168   \n",
       "2569       23  110.0         222        5fde554b85dbbb5cf9a1d168   \n",
       "\n",
       "      Reaction Time                                           Response  \\\n",
       "0       5812.220000  What public schools teach their students is co...   \n",
       "1       5300.000000           And that consists of a number of factors   \n",
       "2       9964.815000    Dad of a stagnant fermentation shrimp of doubts   \n",
       "3      11878.520000  Brisbane corp distant and finished commandos c...   \n",
       "4      12686.870000  Listening those studied bails heater understan...   \n",
       "...             ...                                                ...   \n",
       "2565    1467.500000              List of people in America who hate it   \n",
       "2566    2621.625001  Lions in his most charming little extraterrest...   \n",
       "2567    2137.399999  Immediately after completing algorithms the ga...   \n",
       "2568    1881.740000        The man sleeps with the second solid object   \n",
       "2569    2625.890001  Anyone electron elevation ponies circulate the...   \n",
       "\n",
       "                                              sentence1  \\\n",
       "0                I can not long conceal my dreadful sin   \n",
       "1              And that consists of a number of factors   \n",
       "2       Dad of a stagnant fermentation shrimp of doubts   \n",
       "3     Brisbane corp distant and finished commandos c...   \n",
       "4         Hours into cults cables help arrive in mounts   \n",
       "...                                                 ...   \n",
       "2565  Blog negative blog shelve grammar represents c...   \n",
       "2566  Forces bucks hometown donors Berger complicati...   \n",
       "2567  Danny Louvre shrouded typically flees offendin...   \n",
       "2568  Hart bitter motions Toledo going whacking emer...   \n",
       "2569  Anyone electron elevation ponies circulate the...   \n",
       "\n",
       "                                              sentence2     source  \\\n",
       "0     What public schools teach their students is co...   internet   \n",
       "1            Birmingham but the heavy duty cell one and  generator   \n",
       "2     Mel causal that foothold overflowed paid Cpl a...  generator   \n",
       "3     The frustrating and bananas and the modificati...  generator   \n",
       "4     Listening those studied bails heater understan...  generator   \n",
       "...                                                 ...        ...   \n",
       "2565              List of people in America who hate it  generator   \n",
       "2566  Lions in his most charming little extraterrest...  generator   \n",
       "2567  Immediately after completing algorithms the ga...  generator   \n",
       "2568        The man sleeps with the second solid object  generator   \n",
       "2569  Want sits preaching subscription as spotlights...  generator   \n",
       "\n",
       "     sentence1_model_name sentence2_model_name  sentence1_model_level  \\\n",
       "0                     xlm                  xlm                      1   \n",
       "1                 electra              electra                      9   \n",
       "2                  bilstm               bilstm                      5   \n",
       "3                  bigram               bigram                      2   \n",
       "4                    lstm                 lstm                      5   \n",
       "...                   ...                  ...                    ...   \n",
       "2565                  xlm                  xlm                      3   \n",
       "2566              trigram              trigram                      1   \n",
       "2567              roberta              roberta                      1   \n",
       "2568                  xlm                  xlm                      1   \n",
       "2569               bigram               bigram                      1   \n",
       "\n",
       "      sentence2_model_level  Choice  \\\n",
       "0                         0     1.0   \n",
       "1                         5     0.0   \n",
       "2                         0     0.0   \n",
       "3                         6     0.0   \n",
       "4                         2     1.0   \n",
       "...                     ...     ...   \n",
       "2565                      9     1.0   \n",
       "2566                      5     1.0   \n",
       "2567                      6     1.0   \n",
       "2568                      8     1.0   \n",
       "2569                      2     0.0   \n",
       "\n",
       "                                       sentence_pair_id  \n",
       "0     I can not long conceal my dreadful sin_What pu...  \n",
       "1     And that consists of a number of factors_Birmi...  \n",
       "2     Dad of a stagnant fermentation shrimp of doubt...  \n",
       "3     Brisbane corp distant and finished commandos c...  \n",
       "4     Hours into cults cables help arrive in mounts_...  \n",
       "...                                                 ...  \n",
       "2565  Blog negative blog shelve grammar represents c...  \n",
       "2566  Forces bucks hometown donors Berger complicati...  \n",
       "2567  Danny Louvre shrouded typically flees offendin...  \n",
       "2568  Hart bitter motions Toledo going whacking emer...  \n",
       "2569  Anyone electron elevation ponies circulate the...  \n",
       "\n",
       "[2570 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate negative log-likelihood of choice predictions given as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NLL(subject_data,predictions,mode='sum',deal_with_missing_predictions='omit',return_non_agg_NLL=False):\n",
    "    if 'subject' in predictions.columns: # predictions are subject-specific        \n",
    "        df=subject_data.merge(predictions,how='left',on=['sentence_pair_id','subject'])\n",
    "    else: # same predictions for all subjects\n",
    "        df=subject_data.merge(predictions,how='left',on=['sentence_pair_id'])\n",
    "    c=np.asarray(subject_data.Choice,dtype=float)\n",
    "    df['p']=np.where(c==0,df.choice_0_prob,df.choice_1_prob)    \n",
    "    df['p']=np.where(np.isnan(c),np.nan,df['p'])\n",
    "    \n",
    "    # deal with trials for which we have no predictions:\n",
    "    missing_predictions=np.logical_and(df['p'].isna(),np.logical_not(np.isnan(c))) # there's no prediction but the subject made a choice\n",
    "    \n",
    "    if np.any(missing_predictions):\n",
    "        print('Found {} missing predictions. Handling strategy: {}.'.format(np.sum(missing_predictions),deal_with_missing_predictions))\n",
    "        if deal_with_missing_predictions=='omit':\n",
    "            df=df.loc[np.logical_not(missing_predictions),:] # drop these trails\n",
    "        elif deal_with_missing_predictions=='uniform predictions':\n",
    "            df[missing_predictions,'p']=0.5 # make a uniform prediction\n",
    "        else:\n",
    "            raise ValueError(\"invalid deal_with_missing_predictions\")\n",
    "    \n",
    "    # calculate NLL\n",
    "    df['NLL']=-np.log(df['p'])\n",
    "    if mode=='sum':\n",
    "        agg_NLL=df.NLL.sum().item()        \n",
    "    elif mode=='mean':\n",
    "        agg_NLL=df.NLL.mean().item()\n",
    "    if return_non_agg_NLL:\n",
    "        return agg_NLL, df\n",
    "    else:\n",
    "        return agg_NLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper and lower bounds on the noise ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper noise ceiling NLL 1142.902361691926\n"
     ]
    }
   ],
   "source": [
    "def get_ub_noise_ceiling_predictions(subject_data):    \n",
    "    # calculate human choice probability per sentence (collapsed over subjects and within-subject repetitions)\n",
    "    df=subject_data.copy()\n",
    "    df['chose_0']=np.asarray(subject_data.Choice==0,np.float)\n",
    "    df['chose_0'].loc[np.isnan(subject_data.Choice)]==np.nan\n",
    "    df2=df.groupby('sentence_pair_id')['chose_0'].mean()\n",
    "    df2=df2.drop(columns=['subject']).reset_index().rename(columns={'chose_0':'choice_0_prob'})\n",
    "    df2['choice_1_prob']=1.0-np.asarray(df2.choice_0_prob)\n",
    "    return df2\n",
    "ub_NC_predictions=get_ub_noise_ceiling_predictions(protocol)\n",
    "\n",
    "def get_lb_noise_ceiling_predictions(subject_data):\n",
    "    # calculate leave-one-subject out human choice probability per sentence (collapsed over subjects and within-subject repetitions)\n",
    "    subjects=list(np.unique(subject_data.subject))\n",
    "    df1=subject_data.copy()\n",
    "    df1['chose_0']=np.asarray(df1.Choice==0,np.float)\n",
    "    df1['chose_0'].loc[np.isnan(df1.Choice)]==np.nan\n",
    "    \n",
    "    subject_specific_predictions_dfs=[]\n",
    "    for subject in subjects: # leave one-subject out cross-validation:\n",
    "        without_subject_df=df1.copy().loc[df1.subject!=subject,:] # hold out one subject            \n",
    "        subject_specific_predictions=without_subject_df.groupby('sentence_pair_id')['chose_0'].mean() # mean choice probabilities of the remaining subjects        \n",
    "        subject_specific_predictions=subject_specific_predictions.reset_index().rename(columns={'chose_0':'choice_0_prob'})\n",
    "        subject_specific_predictions['choice_1_prob']=1.0-np.asarray(subject_specific_predictions.choice_0_prob)                \n",
    "        subject_specific_predictions.loc[:,'subject']=subject # we mark the resulting predictions as subject-specific predictions\n",
    "        \n",
    "        # next, we remove predictions for sentence pairs the subject didn't see:\n",
    "        cur_subject_df=df1.copy().loc[df1.subject==subject,:] \n",
    "        cur_subject_sentence_pair_ids=np.unique(cur_subject_df.sentence_pair_id) # these are the sentences the subject saw\n",
    "        subject_specific_predictions=subject_specific_predictions.loc[np.in1d(subject_specific_predictions.sentence_pair_id,cur_subject_sentence_pair_ids),:]                \n",
    "        subject_specific_predictions_dfs.append(subject_specific_predictions) # and add the remaining predictions to the list\n",
    "    \n",
    "    lb_NC_predictions=pd.concat(subject_specific_predictions_dfs)\n",
    "    \n",
    "    return lb_NC_predictions\n",
    "lb_NC_predictions=get_lb_noise_ceiling_predictions(protocol)\n",
    "    \n",
    "ub_NC_NLL=evaluate_NLL(protocol,ub_NC_predictions,mode='sum')\n",
    "print(\"upper noise ceiling NLL\",ub_NC_NLL)\n",
    "\n",
    "# # without a Gamma parameter, the lower noise ceiling can be infinity\n",
    "# lb_NC_NLL,df=evaluate_NLL(protocol,lb_NC_predictions,mode='sum',return_non_agg_NLL=True)\n",
    "# print(\"lower noise ceiling NLL\",lb_NC_NLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Original fitsets generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_stim=pd.read_excel('contstim_pilot_n11_spreadsheet.xlsx')\n",
    "# task_data=pd.read_csv(task_data_csv)\n",
    "\n",
    "# models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2']\n",
    "\n",
    "# prob_dict=dict()\n",
    "# for model_name in [m for m in models if m != \"human_probs\"]:\n",
    "#     f = open(model_name+'_expt1_sentence_probs.pkl','rb')\n",
    "#     dict1=pickle.load(f)\n",
    "#     prob_dict[model_name]=dict1\n",
    "    \n",
    "    \n",
    "# events=list(task_data['Event Index'])\n",
    "# start_inds=[i for i,e in enumerate(events) if e=='1']\n",
    "\n",
    "# fitsets=[]\n",
    "\n",
    "# all_sents=[]\n",
    "\n",
    "# item_responses=dict()\n",
    "\n",
    "# for i,start_ind in enumerate(start_inds):\n",
    "\n",
    "#     setnum=task_data['counterbalance-o1ql'][start_ind]\n",
    "\n",
    "#     if i==12:\n",
    "#         setnum='set 12'\n",
    "\n",
    "#     sub=task_data['Participant External Session ID'][start_ind]\n",
    "\n",
    "#     model1_list=list(task_stim['sentence1_model_'+setnum])[1:]\n",
    "#     model2_list=list(task_stim['sentence2_model_'+setnum])[1:]\n",
    "#     sent1_list=list(task_stim['sentence1_'+setnum])[1:]\n",
    "#     sent2_list=list(task_stim['sentence2_'+setnum])[1:]\n",
    "\n",
    "#     if setnum=='set 1':\n",
    "#         source_list=list(task_stim['source'])[1:]\n",
    "\n",
    "#     else:\n",
    "#         source_list=list(task_stim['source_'+setnum])[1:]\n",
    "\n",
    "#     if i<len(start_inds)-1:\n",
    "#         responses_list=list(task_data['Response'][start_ind:start_inds[i+1]])\n",
    "\n",
    "#     else:\n",
    "#         responses_list=list(task_data['Response'][start_ind:])\n",
    "\n",
    "#     responses_list=[r for r in responses_list if str(r)!='nan']\n",
    "\n",
    "#     item_ids=[]\n",
    "\n",
    "#     fitset=[]\n",
    "    \n",
    "#     for t in range(110):\n",
    "\n",
    "#         source=source_list[t]\n",
    "\n",
    "#         model1=model1_list[t]\n",
    "#         model2=model2_list[t]\n",
    "#         sent1=sent1_list[t]\n",
    "#         sent2=sent2_list[t]\n",
    "        \n",
    "#         all_sents.append(sent1)\n",
    "#         all_sents.append(sent2)\n",
    "\n",
    "#         model1_name=model1[:-2]\n",
    "#         model2_name=model2[:-2]        \n",
    "\n",
    "#         model_ind=models.index(model1_name)\n",
    "\n",
    "#         sents=[sent1,sent2]\n",
    "#         sents_unsort=[sent1,sent2]     \n",
    "#         sents.sort()\n",
    "#         item_id='_'.join(sents)\n",
    "        \n",
    "#         response=responses_list[t]\n",
    "        \n",
    "#         if item_id in item_ids:\n",
    "#             continue\n",
    "            \n",
    "#         if item_id not in item_responses:\n",
    "#             item_responses[item_id]=[sents_unsort.index(response)]\n",
    "#         else:\n",
    "#             item_responses[item_id].append(sents_unsort.index(response))\n",
    "        \n",
    "#         item_ids.append(item_id)\n",
    "\n",
    "#         response_ind=[sent1,sent2].index(response)     \n",
    "        \n",
    "#         for model_name in models[:11]:#[model1_name]\n",
    "\n",
    "#             log_p1=prob_dict[model_name][sent1]\n",
    "#             log_p2=prob_dict[model_name][sent2]\n",
    "\n",
    "#             fitset.append([model_name,log_p1,log_p2,response_ind])\n",
    "            \n",
    "#         #log_human_p1=item_prob_ceilings[item_id][0]\n",
    "#         #log_human_p2=item_prob_ceilings[item_id][1]\n",
    "        \n",
    "#         #fitset.append(['human_probs',log_human_p1,log_human_p2,response_ind])\n",
    "        \n",
    "#     fitsets.append(fitset)\n",
    "\n",
    "# fitsets_all=[]\n",
    "# for fitset in fitsets:\n",
    "#     fitsets_all+=fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_sentence_probs(p_choice_1,p_choice_2,pseudo_sentence_prob_gamma=1.234,eps=1e-8):\n",
    "    p_choice_1=np.clip(p_choice_1,eps,1-eps)\n",
    "    p_choice_2=np.clip(p_choice_2,eps,1-eps)\n",
    "    \n",
    "    s1a_b=-np.log((1-p_choice_1)/p_choice_1)*pseudo_sentence_prob_gamma  \n",
    "    lp1=-100+s1a_b/2\n",
    "    lp2=-100-s1a_b/2\n",
    "\n",
    "    return lp1,lp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised fitsets generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['bigram','trigram','rnn','lstm','bilstm','bert','bert_whole_word','roberta','xlm','electra','gpt2','ub_NC','lb_NC']\n",
    "\n",
    "comp_models=list(np.setdiff1d(models,['ub_NC','lb_NC']))\n",
    "human_models=list(np.setdiff1d(models,comp_models))\n",
    "\n",
    "prob_dict=dict()\n",
    "for model_name in comp_models:\n",
    "    f = open(model_name+'_expt1_sentence_probs.pkl','rb')\n",
    "    prob_dict[model_name]=pickle.load(f)\n",
    "\n",
    "fitsets=[]\n",
    "for i_subject in range(n_subjects):\n",
    "    cur_sub_protocol=protocol.loc[protocol.subject==i_subject,:]\n",
    "    \n",
    "    fitset=[]\n",
    "    for i_trial, trial in cur_sub_protocol.iterrows():\n",
    "        for model_name in models:\n",
    "            if model_name in comp_models:\n",
    "                log_p1=prob_dict[model_name][trial.sentence1]\n",
    "                log_p2=prob_dict[model_name][trial.sentence2]\n",
    "                fitset.append([model_name,log_p1,log_p2,trial.Choice])\n",
    "            if model_name in human_models:\n",
    "                # get predictions from dataframe \n",
    "                predictions_df={'ub_NC':ub_NC_predictions,'lb_NC':lb_NC_predictions}[model_name]                \n",
    "                if 'subject' in predictions_df.columns: # deal with subject-specific predictions\n",
    "                    filter_vars=['sentence_pair_id','subject']\n",
    "                else:\n",
    "                    filter_vars=['sentence_pair_id']\n",
    "                    \n",
    "                cur_prediction=trial.to_frame().T.merge(predictions_df,how='left',on=filter_vars)\n",
    "                assert len(cur_prediction)==1, 'exactly one prediction should be provided for each trial (found {} for subject {}: {}).'.format(len(cur_prediction),trial.subject,trial.sentence_pair_id)\n",
    "                                    \n",
    "                p1=cur_prediction.loc[0,'choice_0_prob']\n",
    "                p2=cur_prediction.loc[0,'choice_1_prob']\n",
    "                \n",
    "                assert np.isfinite(p1) and np.isfinite(p2), 'found nan predictions for subject {}: {}).'.format(trial.subject,trial.sentence_pair_id)\n",
    "                \n",
    "                log_p1,log_p2=pseudo_sentence_probs(p1,p2)\n",
    "                fitset.append([model_name,log_p1,log_p2,trial.Choice])\n",
    "            \n",
    "    fitsets.append(fitset)\n",
    "\n",
    "fitsets_all=[]\n",
    "for fitset in fitsets:\n",
    "    fitsets_all+=fitset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "minps=[]\n",
    "for m in models:\n",
    "    m=np.min([np.min([trial[1],trial[2]]) for trial in fitsets_all if trial[0]==m])\n",
    "    minps.append(m)\n",
    "    \n",
    "minps=np.abs(minps)\n",
    "\n",
    "\n",
    "maxps=[]\n",
    "for m in models:\n",
    "    m=np.max([np.max([trial[1],trial[2]]) for trial in fitsets_all if trial[0]==m])\n",
    "    maxps.append(m)\n",
    "    \n",
    "maxps=np.abs(maxps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overflow within exponentials when calculating probabilities, we'll use torch.logsumexp where log(exp(x)+1) is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(1+exp(x)) | direct implementation: tensor([ 0.0000, 50.0000,  0.3133,  0.6931,  1.3133, 50.0000,     inf])\n",
      "log(1+exp(x)) | with logsumexp: tensor([  0.0000,  50.0000,   0.3133,   0.6931,   1.3133,  50.0000, 100.0000])\n",
      "log(1/(1+exp(x))) | direct implementation: tensor([  0.0000, -50.0000,  -0.3133,  -0.6931,  -1.3133, -50.0000,     -inf])\n",
      "log(1/(1+exp(x))) | with logsumexp: tensor([  -0.0000,  -50.0000,   -0.3133,   -0.6931,   -1.3133,  -50.0000,\n",
      "        -100.0000])\n",
      "log(1 - 1/(1+exp(x))) | direct implementation: tensor([   -inf,  0.0000, -1.3133, -0.6931, -0.3133,  0.0000,  0.0000])\n",
      "log(1 - 1/(1+exp(x))) | with logsumexp: tensor([-100.0000,    0.0000,   -1.3133,   -0.6931,   -0.3133,    0.0000,\n",
      "           0.0000])\n"
     ]
    }
   ],
   "source": [
    "# this is mathemathically eqivalent to torch.log(1+torch.exp(x)) but it doesn't overflow when x is big.\n",
    "log_1_plus_exp_x=lambda x: torch.logsumexp(torch.stack((x,torch.zeros_like(x)),dim=-1),dim=1)\n",
    "\n",
    "# this is mathemathically equivalent to log(1/(1+exp(x)))\n",
    "log_p=lambda x: -log_1_plus_exp_x(x) \n",
    "\n",
    "# this is mathemathically equivalent to log(1 - 1/(1+exp(x)) )\n",
    "log_1_minus_p=lambda x: x+log_p(x)\n",
    "\n",
    "x=torch.tensor([-100.0,50.0,-1.0,0.0,1.0,50.0,100.0])\n",
    "print('log(1+exp(x)) | direct implementation:', torch.log(1+torch.exp(x)))\n",
    "print('log(1+exp(x)) | with logsumexp:', log_1_plus_exp_x(x))\n",
    "\n",
    "print('log(1/(1+exp(x))) | direct implementation:', torch.log(1/(1+torch.exp(x))))\n",
    "print('log(1/(1+exp(x))) | with logsumexp:', log_p(x))\n",
    "\n",
    "print('log(1 - 1/(1+exp(x))) | direct implementation:', torch.log(1-1/(1+torch.exp(x))))\n",
    "print('log(1 - 1/(1+exp(x))) | with logsumexp:', log_1_minus_p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelToHumanDecision():\n",
    "    def _set_initial_parameters(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __init__(self,model_name_list,parameters=None,device=None):\n",
    "        if device is None:\n",
    "            device='cpu'\n",
    "        \n",
    "        self.device=torch.device(device)\n",
    "        self.model_name_list=model_name_list\n",
    "        self.n_models=len(model_name_list)\n",
    "        \n",
    "        if parameters is None:\n",
    "            self.parameters=self._initial_parameters()\n",
    "        else:\n",
    "            self.parameters={key:torch.tensor(value,device=self.device,dtype=torch.float64) for (key,value) in parameters.items()}\n",
    "\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def decision_NLL(self,log_p1,log_p2,model=None):\n",
    "        \n",
    "        log_p1=torch.as_tensor(log_p1,device=self.device,dtype=torch.float64)\n",
    "        log_p2=torch.as_tensor(log_p2,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        if model is None: # evaluate all models. # log_p1, log_p2 (n_models,n_sentence_pairs)\n",
    "            assert log_p1.ndim==2 and log_p1.shape[0]==self.n_models and log_p2.ndim==3 and log_p2.shape[0]==self.n_models \n",
    "            slicer=...\n",
    "        elif type(model) is str: # one particular model specified by its name\n",
    "            slicer=self.model_name_list.index(model)\n",
    "        elif type(model) is int: # one particular model specified by its index\n",
    "            slicer=model\n",
    "        elif type(model) is list: # a list of model names\n",
    "            slicer=torch.tensor([self.model_name_list.index(m) for m in model])\n",
    "        else:\n",
    "            raise \n",
    "        cur_parameters={}\n",
    "        \n",
    "#         print(self.parameters.items())\n",
    "#         sys.e\n",
    "        \n",
    "        for par_name, par in self.parameters.items():\n",
    "            if par.nelement()==1:\n",
    "                cur_parameters[par_name]=par\n",
    "            else:\n",
    "                cur_parameters[par_name]=par[slicer]\n",
    "        return self._f(log_p1,log_p2,cur_parameters)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        numpy_parameters={}\n",
    "        for par_name, par in self.parameters.items():\n",
    "            if par.nelement()==1:\n",
    "                numpy_parameters[par_name]=par.item()\n",
    "            else:\n",
    "                numpy_parameters[par_name]=par.detach().cpu().numpy()\n",
    "        return numpy_parameters\n",
    "\n",
    "class FixedWidthSquashing(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.tensor(10.0,device=self.device)\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=1.0\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))        \n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL\n",
    "\n",
    "    \n",
    "class FixedWidthSquashingVariableGamma(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        return parameters\n",
    "    \n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=1.0\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "        #log_p1_corrected=width*torch.log(1+math.e**((log_p1+squash_threshold)/width))-squash_threshold\n",
    "        #log_p2_corrected=width*torch.log(1+math.e**((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL\n",
    "\n",
    "class VariableWidthSquashing(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.tensor(10.0,device=self.device)\n",
    "        parameters['width']=torch.ones(self.n_models,device=self.device)        \n",
    "        return parameters\n",
    "    \n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=torch.nn.Softplus()(cur_parameters['width'])+1e-1\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "#         log_p1_corrected=width*torch.log(1+torch.exp((log_p1+squash_threshold)/width))-squash_threshold\n",
    "#         log_p2_corrected=width*torch.log(1+torch.exp((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "\n",
    "\n",
    "class VariableWidthSquashingVariableGamma(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['squashes']=torch.ones(self.n_models,device=self.device)*200.0 # this doesn't work\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        parameters['width']=torch.ones(self.n_models,device=self.device)\n",
    "\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        squash_threshold=cur_parameters['squashes']     \n",
    "        width=torch.nn.Softplus()(cur_parameters['width'])+1e-1\n",
    "        log_p1_corrected=width*log_1_plus_exp_x((log_p1+squash_threshold)/width)-squash_threshold\n",
    "        log_p2_corrected=width*log_1_plus_exp_x((log_p2+squash_threshold)/width)-squash_threshold\n",
    "#         log_p1_corrected=width*torch.log(1+math.e**((log_p1+squash_threshold)/width))-squash_threshold\n",
    "#         log_p2_corrected=width*torch.log(1+math.e**((log_p2+squash_threshold)/width))-squash_threshold\n",
    "        s1a_b = log_p1_corrected - log_p2_corrected\n",
    "        log_p1=log_p(-s1a_b/gamma)\n",
    "        log_p2=log_1_minus_p(-s1a_b/gamma)\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "#         p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "#         p2=1-p1\n",
    "#         choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "    \n",
    "\n",
    "class VariableGammaNoSquash(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        s1a_b = log_p1 - log_p2\n",
    "        p1=1/(1+torch.exp(-(s1a_b)/gamma))\n",
    "        p2=1-p1\n",
    "        choice_NLL=-torch.log(torch.stack([p1,p2],dim=-1))\n",
    "        return choice_NLL\n",
    "    \n",
    "class SquashedSoftmax(ModelToHumanDecision):\n",
    "    def _initial_parameters(self):\n",
    "        parameters={}\n",
    "        parameters['gamma']=torch.ones(self.n_models,device=self.device)*10.0\n",
    "        parameters['eta']=torch.ones(self.n_models,device=self.device)*(0.0)\n",
    "        return parameters\n",
    "    def _f(self,log_p1,log_p2,cur_parameters):\n",
    "        gamma=cur_parameters['gamma']\n",
    "        eta=cur_parameters['eta']\n",
    "        \n",
    "        denominator=torch.logsumexp(torch.stack([log_p1/gamma,torch.ones_like(log_p1)*eta,log_p2/gamma,torch.ones_like(log_p2)*eta],dim=-1),dim=-1)\n",
    "        log_p1 = torch.logsumexp(torch.stack([log_p1/gamma,torch.ones_like(log_p1)*eta],dim=-1),dim=-1)-denominator\n",
    "        log_p2 = torch.logsumexp(torch.stack([log_p2/gamma,torch.ones_like(log_p2)*eta],dim=-1),dim=-1)-denominator\n",
    "        choice_NLL=-torch.stack([log_p1,log_p2],dim=-1)\n",
    "        return choice_NLL    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "loss: tensor(28257.2715, grad_fn=<AddBackward0>)\n",
      "squashes tensor([172.6353, 158.2039, 186.6036, 191.4571, 141.2743, 151.7397, 150.0234,\n",
      "        151.1320, 147.1514, 134.0681, 128.9228, 111.3656, 111.3656],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "\n",
      "loss: tensor(20062.1191, grad_fn=<AddBackward0>)\n",
      "squashes tensor([164.2733, 153.8807, 107.3920, 108.8043,  97.3009, 110.2292, 102.1113,\n",
      "        112.2374, 102.9731,  96.0446, 103.2400, 120.4756, 105.0292],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([28.3216, 29.7767, 35.5419, 36.3204, 30.7373, 31.5910, 32.6576, 30.7484,\n",
      "        32.4145, 30.7817, 31.0175,  1.2301, 17.2154], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20057.7148, grad_fn=<AddBackward0>)\n",
      "squashes tensor([173.5280, 160.3739, 107.8170, 110.2743,  96.4124, 114.0238, 104.8003,\n",
      "        113.4206, 104.9947,  95.6767, 105.7097, 120.4769, 102.5511],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.6877, 31.2998, 35.8889, 36.8958, 29.7425, 32.8871, 33.6249, 31.2395,\n",
      "        33.4133, 30.7104, 32.5207,  1.2339, 14.1377], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20057.0156, grad_fn=<AddBackward0>)\n",
      "squashes tensor([174.7262, 161.0684, 108.0482, 110.7974,  95.9280, 115.4934, 107.2234,\n",
      "        113.6833, 108.9129,  95.6422, 106.1554, 120.4769, 102.5942],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8034, 31.3614, 36.1540, 37.3537, 29.2668, 33.6846, 34.7129, 31.4442,\n",
      "        34.4036, 30.6775, 32.9281,  1.2340, 14.1971], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20054.4648, grad_fn=<AddBackward0>)\n",
      "squashes tensor([175.2340, 161.5320, 108.2028, 111.1837,  95.7872, 116.1880, 108.4891,\n",
      "        113.7604, 136.0257,  95.6362, 106.2218, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8031, 31.3614, 36.3195, 37.6777, 29.1323, 34.0087, 35.5044, 31.5031,\n",
      "        36.7935, 30.6712, 32.9904,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20054.1797, grad_fn=<AddBackward0>)\n",
      "squashes tensor([175.6064, 161.8867, 108.2822, 111.4263,  95.7611, 116.5620, 109.0445,\n",
      "        113.7766, 133.6295,  95.6355, 106.2274, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8033, 31.3616, 36.4061, 37.8807, 29.1076, 34.1434, 35.8760, 31.5154,\n",
      "        38.0355, 30.6705, 32.9956,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20054.1719, grad_fn=<AddBackward0>)\n",
      "squashes tensor([175.9046, 162.1764, 108.3175, 111.5634,  95.7579, 116.8661, 109.2922,\n",
      "        113.7790, 133.6350,  95.6355, 106.2276, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8034, 31.3616, 36.4449, 37.9954, 29.1046, 34.2240, 36.0291, 31.5172,\n",
      "        38.1291, 30.6704, 32.9958,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20054.1641, grad_fn=<AddBackward0>)\n",
      "squashes tensor([176.1553, 162.4224, 108.3311, 111.6335,  95.7577, 118.0141, 109.4009,\n",
      "        113.7792, 133.6368,  95.6355, 106.2276, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8035, 31.3617, 36.4600, 38.0541, 29.1044, 34.3583, 36.0915, 31.5174,\n",
      "        38.1337, 30.6704, 32.9958,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20053.2227, grad_fn=<AddBackward0>)\n",
      "squashes tensor([176.3727, 162.6369, 108.3357, 111.6661,  95.7577, 131.1955, 109.4465,\n",
      "        113.7792, 133.6369,  95.6355, 106.2276, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8035, 31.3617, 36.4650, 38.0814, 29.1044, 36.0455, 36.1166, 31.5174,\n",
      "        38.1339, 30.6704, 32.9958,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20053.2188, grad_fn=<AddBackward0>)\n",
      "squashes tensor([176.5653, 162.8278, 108.3370, 111.6798,  95.7577, 131.2706, 109.4642,\n",
      "        113.7792, 133.6369,  95.6355, 106.2276, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8036, 31.3617, 36.4664, 38.0928, 29.1044, 36.0564, 36.1262, 31.5174,\n",
      "        38.1339, 30.6704, 32.9958,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20053.2188, grad_fn=<AddBackward0>)\n",
      "squashes tensor([176.7387, 163.0001, 108.3373, 111.6850,  95.7577, 131.2691, 109.4706,\n",
      "        113.7792, 133.6369,  95.6355, 106.2276, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8036, 31.3617, 36.4668, 38.0972, 29.1044, 36.0563, 36.1296, 31.5174,\n",
      "        38.1339, 30.6704, 32.9958,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "loss: tensor(20053.2188, grad_fn=<AddBackward0>)\n",
      "squashes tensor([176.8968, 163.1576, 108.3374, 111.6867,  95.7577, 131.2690, 109.4726,\n",
      "        113.7792, 133.6369,  95.6355, 106.2276, 120.4769, 102.5946],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "gamma tensor([29.8036, 31.3618, 36.4669, 38.0987, 29.1044, 36.0563, 36.1307, 31.5174,\n",
      "        38.1339, 30.6704, 32.9958,  1.2340, 14.1977], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "\n",
      "{'squashes': array([176.91358053, 163.17429549, 108.33737892, 111.68683463,\n",
      "        95.75765466, 131.26903491, 109.47273007, 113.77922638,\n",
      "       133.63687155,  95.63550124, 106.22759205, 120.47687398,\n",
      "       102.59461066]), 'gamma': array([29.8036137 , 31.36175558, 36.4668859 , 38.09875642, 29.10435656,\n",
      "       36.05626332, 36.13075719, 31.51738089, 38.13385175, 30.67042073,\n",
      "       32.9958312 ,  1.23399946, 14.19768799])}\n",
      "total loss: tensor(20053.2188, grad_fn=<AddBackward0>)\n",
      "bigram 1562.32\n",
      "trigram 1566.99\n",
      "rnn 1571.77\n",
      "lstm 1562.92\n",
      "bilstm 1569.95\n",
      "bert 1571.21\n",
      "bert_whole_word 1575.73\n",
      "roberta 1561.23\n",
      "xlm 1570.43\n",
      "electra 1560.68\n",
      "gpt2 1557.89\n",
      "ub_NC 1142.90\n",
      "lb_NC 1679.21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':10.0}\n",
    "# model_class=FixedWidthSquashing\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':10.0,'width':np.ones(len(models))}\n",
    "# model_class=VariableWidthSquashing\n",
    "\n",
    "parameters={'squashes':minps,'gamma':np.ones_like(minps)*10.0}\n",
    "model_class=FixedWidthSquashingVariableGamma\n",
    "\n",
    "# parameters={'gamma':np.ones_like(minps)*10.0}\n",
    "# model_class=VariableGammaNoSquash\n",
    "\n",
    "# parameters={'squashes':minps,'gamma':np.ones_like(minps)*10.0,'width':np.ones(len(models))}\n",
    "# model_class=VariableWidthSquashingVariableGamma\n",
    "\n",
    "# parameters=None # use defaults\n",
    "# model_class=SquashedSoftmax\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "assert len(fitsets)==n_subjects\n",
    "\n",
    "for boot in range(1):\n",
    "    \n",
    "#     boots=np.random.choice(n_subjects, n_subjects)\n",
    "    boots=np.arange(n_subjects)\n",
    "    \n",
    "    fitset=[]\n",
    "    for b in boots:\n",
    "        fitset+=fitsets[b]\n",
    "    \n",
    "    decision_model=model_class(model_name_list=models,parameters=parameters,device=device)\n",
    "\n",
    "    for par in decision_model.parameters.values():\n",
    "        par.requires_grad=True\n",
    "        \n",
    "    opt = optim.Adam(decision_model.parameters.values(),lr=1)\n",
    "\n",
    "    print(boot)\n",
    "    print('')\n",
    "\n",
    "    # build models by trials by sentences log-prob matrix\n",
    "    \n",
    "    log_p1=defaultdict(list)\n",
    "    log_p2=defaultdict(list)\n",
    "    response_ind=defaultdict(list)\n",
    "    \n",
    "    for trial in fitset:\n",
    "        model1_name=trial[0]\n",
    "        log_p1[model1_name].append(trial[1])\n",
    "        log_p2[model1_name].append(trial[2])\n",
    "        response_ind[model1_name].append(trial[3])\n",
    "        \n",
    "    \n",
    "    for epoch in range(1000): # for some models, one needs more than 200 epochs for convergence. I'd replace this loop with a convergence criterion.\n",
    "\n",
    "        loss = torch.tensor(0.,device=device,requires_grad = True)\n",
    "        \n",
    "        model_loss=torch.zeros((len(models)),device=device)\n",
    "        \n",
    "        for i_model,model1_name in enumerate(models):\n",
    "            log_p_sent=decision_model.decision_NLL(log_p1[model1_name],log_p2[model1_name],model=model1_name)\n",
    "            take_by_2nd_dim=lambda x, idx: x[torch.arange(x.size(0)), idx] \n",
    "            log_p_choice=take_by_2nd_dim(log_p_sent,response_ind[model1_name])\n",
    "            model_loss[i_model]=log_p_choice.sum()\n",
    "            loss=loss+model_loss[i_model]\n",
    "            \n",
    "        if epoch%90==0:\n",
    "            print('loss:',loss)\n",
    "            for par_name, par in decision_model.parameters.items():\n",
    "                print(par_name,par)\n",
    "            print('')\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    print(decision_model.get_parameters())\n",
    "    print('total loss:',loss)\n",
    "    for i_model,model1_name in enumerate(models):\n",
    "        print('{} {:.2f}'.format(model1_name,model_loss[i_model].item()))\n",
    "        \n",
    "    squashes=list(decision_model.parameters['squashes'].data.numpy())\n",
    "    gammas=list(decision_model.parameters['gamma'].data.numpy())\n",
    "    #gammas=float(decision_model.parameters['gamma'])\n",
    "    \n",
    "    if boot==0:\n",
    "        squash_boots=[squashes]\n",
    "        gamma_boots=[gammas]\n",
    "        losses=[m.item() for m in model_loss]\n",
    "    else:\n",
    "        squash_boots.append(squashes)\n",
    "        gamma_boots.append(gammas)\n",
    "        losses.append([m.item() for m in model_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/numpy/lib/function_base.py:2551: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/numpy/lib/function_base.py:2480: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/tal/anaconda3/envs/cuda10.1/lib/python3.7/site-packages/numpy/lib/function_base.py:2480: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gT=np.array(gamma_boots).T\n",
    "sT=np.array(squash_boots).T\n",
    "\n",
    "ccs=[]\n",
    "for i in range(11):\n",
    "    \n",
    "    cc=np.corrcoef(sT[i,:],gT[i,:])[0,1]\n",
    "    ccs.append(cc)\n",
    "    \n",
    "ccs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synthetic\n",
    "\n",
    "# tensor(671.4779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([129.5626, 128.7844,  84.1193,  92.4041, 111.8108, 105.3416,  83.8154,\n",
    "#         116.5818,  87.0363,  60.6492,  81.0560], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([29.8585, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n",
    "\n",
    "\n",
    "#natural\n",
    "\n",
    "# tensor(148.7837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([115.8415,  84.2844,  72.0876,  43.8699,  54.9998,  50.4821,  69.6983,\n",
    "#          49.1065,  42.4528,  34.6840,  59.5816], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([ 9.1418, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n",
    "\n",
    "\n",
    "# tensor(829.6835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor([129.1968, 127.7177,  83.4297,  91.0015, 111.4391, 104.3089,  83.3092,\n",
    "#         115.3282,  85.6379,  59.8025,  79.7266], device='cuda:0',\n",
    "#        dtype=torch.float64, requires_grad=True)\n",
    "# tensor([28.2664, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
    "#         10.0000, 10.0000, 10.0000], device='cuda:0', requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squash_boots=np.array([[136.6031, 130.6315,  88.2857, 127.1014, 124.6718, 110.4878,  84.6417,\n",
    "#         118.1435, 107.7737,  63.0790,  79.9143],\n",
    "#               [137.9003, 125.7105,  84.5635, 127.1772, 112.0871,  94.5774,  78.6344,\n",
    "#         114.0863,  95.4273,  58.2541,  79.6323],\n",
    "#               [131.8761, 133.7181, 147.7142, 143.2530, 110.6293, 134.2203,  83.7578,\n",
    "#         139.0220,  82.7407,  66.7261,  79.2919],\n",
    "#               [139.6443, 135.6945,  80.5810,  94.8058, 116.6113, 103.0531,  87.4392,\n",
    "#         119.7775,  81.2322,  60.9193,  81.1773],\n",
    "#               [132.4967, 128.7608,  92.4549,  91.8489, 110.4346, 104.1544,  80.5317,\n",
    "#         126.0785, 124.9601,  57.4880,  76.9285],\n",
    "#               [128.2988, 112.9426,  80.0811,  90.9844, 111.0652, 115.8396,  56.3730,\n",
    "#          78.9889, 120.2621,  29.6331,  61.9582],\n",
    "#               [127.7181, 132.9688, 148.8201,  94.7272, 109.7225,  87.5404,  81.3132,\n",
    "#         115.8013, 116.9241,  64.7583,  73.5550],\n",
    "#               [120.8540, 116.8421, 135.4461,  88.5892, 124.1079, 133.7935,  86.1704,\n",
    "#         100.1683,  92.7386,  49.7565,  79.4477],\n",
    "#               [125.4391, 114.5180,  82.5459,  87.4416, 110.8198,  93.8739,  63.4568,\n",
    "#         117.9814,  83.9064,  57.2624,  77.2107],\n",
    "#               [129.6447, 129.3590,  86.6444,  92.5276, 109.5141, 105.0256,  65.8152,\n",
    "#         117.5682, 125.8277,  59.4612,  77.8789]])\n",
    "\n",
    "s=squash_boots\n",
    "\n",
    "squash_boots=np.array(losses).T\n",
    "squash_boots.sort()\n",
    "squash_boots=squash_boots.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squash_boots=squash_boots.reshape([10,11])\n",
    "\n",
    "\n",
    "\n",
    "x=np.arange(11)*2\n",
    "# plt.bar(x-0.2, maxps, width=0.1, color=[1,0,0])\n",
    "plt.bar(x-0.1, squash_boots[0], width=0.1, color=[0,0,1])\n",
    "plt.bar(x, squash_boots[1], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.1, squash_boots[2], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.2, squash_boots[3], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.3, squash_boots[4], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.4, squash_boots[5], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.5, squash_boots[6], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.6, squash_boots[7], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.7, squash_boots[8], width=0.1, color=[0,0,1])\n",
    "plt.bar(x+0.8, squash_boots[9], width=0.1, color=[0,0,1])\n",
    "# plt.bar(x+0.9, minps, width=0.1, color=[1,0,0])\n",
    "\n",
    "# plt.ylabel('Squash Thresholds')\n",
    "plt.ylabel('Negative log likelihood')\n",
    "plt.xticks(x,models,rotation=70)\n",
    "\n",
    "# plt.ylim([800,950])\n",
    "\n",
    "legs=['Min/Max baseline','Squash thresholds']\n",
    "# plt.legend(legs,bbox_to_anchor=(1, 0.3, 0.2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=squash_boots.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=np.array([f.sort() for f in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_boots=d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist=list(set(all_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('test_sents_expt1_first13subs.txt','w')\n",
    "for s in slist:\n",
    "    file.write(s)\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model.parameters['squashes'].data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sent1,sent2].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=0\n",
    "a=0\n",
    "for trial in fitset:\n",
    "    \n",
    "    if trial[0]=='electra':\n",
    "        \n",
    "        a+=1\n",
    "    \n",
    "        pa=trial[1]\n",
    "        pb=trial[2]\n",
    "        c=trial[3]\n",
    "\n",
    "        if c==0 and pa>pb:\n",
    "            g+=1\n",
    "        elif c==1 and pb>pa:\n",
    "            g+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g/len(fitset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(item_prob_ceilings[item_id][1])==-math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
