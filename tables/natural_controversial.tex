\begin{tabularx}{\textwidth}{lllc}
\toprule
                                                           sentence &                               log probability (model 1) &                               log probability (model 2) &  \# human choices \\
\midrule
                          $n_1$: I did a Read with Me last weekend. &             $\log p(n_1 | \textrm{GPT-2})=$\num{-51.97} &  $\log p(n_1 | \textrm{ELECTRA})=$\textbf{\num{-34.90}} &  \textbf{\num{1}} \\
                 $n_2$: Kind of an ends justify the means attitude. &    $\log p(n_2 | \textrm{GPT-2})=$\textbf{\num{-31.30}} &           $\log p(n_2 | \textrm{ELECTRA})=$\num{-58.93} &           \num{0} \\\midrule
               $n_1$: Whoever wants to get the vaccine already did. &           $\log p(n_1 | \textrm{RoBERTa})=$\num{-67.74} &     $\log p(n_1 | \textrm{LSTM})=$\textbf{\num{-44.24}} &  \textbf{\num{2}} \\
          $n_2$: Select coupon and discount will apply at checkout. &  $\log p(n_2 | \textrm{RoBERTa})=$\textbf{\num{-53.08}} &              $\log p(n_2 | \textrm{LSTM})=$\num{-79.13} &           \num{0} \\\midrule
 $n_1$: I never disrespect anyone without being disrespected first. &           $\log p(n_1 | \textrm{ELECTRA})=$\num{-59.54} &  $\log p(n_1 | \textrm{RoBERTa})=$\textbf{\num{-54.53}} &  \textbf{\num{1}} \\
                   $n_2$: Being bad feels good on A physical level. &  $\log p(n_2 | \textrm{ELECTRA})=$\textbf{\num{-37.37}} &           $\log p(n_2 | \textrm{RoBERTa})=$\num{-67.33} &           \num{0} \\\midrule
   $n_1$: Nothing worse than getting misunderstood on the internet. &              $\log p(n_1 | \textrm{BERT})=$\num{-71.81} &      $\log p(n_1 | \textrm{XLM})=$\textbf{\num{-45.77}} &  \textbf{\num{1}} \\
                $n_2$: And my game has been working perfectly fine. &     $\log p(n_2 | \textrm{BERT})=$\textbf{\num{-52.61}} &               $\log p(n_2 | \textrm{XLM})=$\num{-69.01} &           \num{0} \\\midrule
                   $n_1$: Then took a pic for fake internet points. &               $\log p(n_1 | \textrm{XLM})=$\num{-66.26} &   $\log p(n_1 | \textrm{3-gram})=$\textbf{\num{-90.16}} &  \textbf{\num{2}} \\
                         $n_2$: The quirks are part of One For All. &      $\log p(n_2 | \textrm{XLM})=$\textbf{\num{-42.12}} &           $\log p(n_2 | \textrm{3-gram})=$\num{-117.02} &           \num{0} \\\midrule
     $n_1$: This article is originally published at Insider Monkey. &              $\log p(n_1 | \textrm{LSTM})=$\num{-72.72} &  $\log p(n_1 | \textrm{RoBERTa})=$\textbf{\num{-41.23}} &  \textbf{\num{1}} \\
                  $n_2$: Neither of them were even allied to Genoa. &     $\log p(n_2 | \textrm{LSTM})=$\textbf{\num{-42.47}} &           $\log p(n_2 | \textrm{RoBERTa})=$\num{-68.78} &           \num{0} \\\midrule
                     $n_1$: The sub can revoke consent at any time. &               $\log p(n_1 | \textrm{RNN})=$\num{-81.48} &  $\log p(n_1 | \textrm{RoBERTa})=$\textbf{\num{-50.84}} &  \textbf{\num{1}} \\
              $n_2$: Maybe because there are so little combo skill. &      $\log p(n_2 | \textrm{RNN})=$\textbf{\num{-48.36}} &           $\log p(n_2 | \textrm{RoBERTa})=$\num{-69.74} &           \num{0} \\\midrule
        $n_1$: Classic case of under promising and over delivering. &           $\log p(n_1 | \textrm{3-gram})=$\num{-128.96} &    $\log p(n_1 | \textrm{GPT-2})=$\textbf{\num{-33.72}} &  \textbf{\num{2}} \\
                        $n_2$: I get out more time and money based. &   $\log p(n_2 | \textrm{3-gram})=$\textbf{\num{-93.73}} &             $\log p(n_2 | \textrm{GPT-2})=$\num{-53.29} &           \num{0} \\\midrule
                $n_1$: Remove and allow to cool completely on rack. &           $\log p(n_1 | \textrm{2-gram})=$\num{-132.00} &    $\log p(n_1 | \textrm{GPT-2})=$\textbf{\num{-30.54}} &  \textbf{\num{2}} \\
                       $n_2$: I live how you really used the title. &  $\log p(n_2 | \textrm{2-gram})=$\textbf{\num{-108.75}} &             $\log p(n_2 | \textrm{GPT-2})=$\num{-54.56} &           \num{0} \\
\bottomrule
\end{tabularx}
