{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence_pair</th>\n",
       "      <th>Trial Number</th>\n",
       "      <th>rating</th>\n",
       "      <th>Response</th>\n",
       "      <th>Reaction Time</th>\n",
       "      <th>counterbalance-o1ql</th>\n",
       "      <th>sentence1_model</th>\n",
       "      <th>sentence2_model</th>\n",
       "      <th>sentence1_type</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence1_model_targeted_to_accept</th>\n",
       "      <th>sentence1_model_targeted_to_reject</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_group</th>\n",
       "      <th>binarized_choice_probability_NC_LB</th>\n",
       "      <th>binarized_choice_probability_NC_UB</th>\n",
       "      <th>majority_vote_NC_LB</th>\n",
       "      <th>majority_vote_NC_UB</th>\n",
       "      <th>mean_rating_NC_LB</th>\n",
       "      <th>mean_rating_NC_UB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A message has been sent to your account_They a...</td>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Confident</td>\n",
       "      <td>3525.1</td>\n",
       "      <td>set 1_10</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A road closure is unlikely to impact service_I...</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Somewhat confident</td>\n",
       "      <td>7541.2</td>\n",
       "      <td>set 1_10</td>\n",
       "      <td>xlm</td>\n",
       "      <td>trigram</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A whole history of kisses just so right_Our cu...</td>\n",
       "      <td>113</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>5099.4</td>\n",
       "      <td>set 1_10</td>\n",
       "      <td>xlm</td>\n",
       "      <td>electra</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>electra</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>About christmas around thanksgiving was really...</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Somewhat confident</td>\n",
       "      <td>5246.1</td>\n",
       "      <td>set 1_10</td>\n",
       "      <td>xlm</td>\n",
       "      <td>bert</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>bert</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>After reward yourself with whatever floats you...</td>\n",
       "      <td>159</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Somewhat confident</td>\n",
       "      <td>5246.8</td>\n",
       "      <td>set 1_10</td>\n",
       "      <td>xlm</td>\n",
       "      <td>trigram</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>trigram</td>\n",
       "      <td>xlm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16495</th>\n",
       "      <td>16495</td>\n",
       "      <td>You can find way better deals than that_You ca...</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>6939.0</td>\n",
       "      <td>set 1_9</td>\n",
       "      <td>roberta</td>\n",
       "      <td>xlm</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>16496</td>\n",
       "      <td>You definitely have to try these other dessert...</td>\n",
       "      <td>103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>11533.0</td>\n",
       "      <td>set 1_9</td>\n",
       "      <td>bigram</td>\n",
       "      <td>roberta</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>roberta</td>\n",
       "      <td>bigram</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16497</th>\n",
       "      <td>16497</td>\n",
       "      <td>You obviously need to speed someone unless and...</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Somewhat confident</td>\n",
       "      <td>10739.0</td>\n",
       "      <td>set 1_9</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>16498</td>\n",
       "      <td>You should douse those women before they charg...</td>\n",
       "      <td>82</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>7674.0</td>\n",
       "      <td>set 1_9</td>\n",
       "      <td>electra</td>\n",
       "      <td>bert</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>bert</td>\n",
       "      <td>electra</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>16499</td>\n",
       "      <td>Your future has less clarity than the picture_...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Confident</td>\n",
       "      <td>9751.0</td>\n",
       "      <td>set 1_9</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16500 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                      sentence_pair  \\\n",
       "0               0  A message has been sent to your account_They a...   \n",
       "1               1  A road closure is unlikely to impact service_I...   \n",
       "2               2  A whole history of kisses just so right_Our cu...   \n",
       "3               3  About christmas around thanksgiving was really...   \n",
       "4               4  After reward yourself with whatever floats you...   \n",
       "...           ...                                                ...   \n",
       "16495       16495  You can find way better deals than that_You ca...   \n",
       "16496       16496  You definitely have to try these other dessert...   \n",
       "16497       16497  You obviously need to speed someone unless and...   \n",
       "16498       16498  You should douse those women before they charg...   \n",
       "16499       16499  Your future has less clarity than the picture_...   \n",
       "\n",
       "       Trial Number  rating            Response  Reaction Time  \\\n",
       "0                66     2.0           Confident         3525.1   \n",
       "1                12     3.0  Somewhat confident         7541.2   \n",
       "2               113     6.0      Very confident         5099.4   \n",
       "3                61     4.0  Somewhat confident         5246.1   \n",
       "4               159     3.0  Somewhat confident         5246.8   \n",
       "...             ...     ...                 ...            ...   \n",
       "16495           101     1.0      Very confident         6939.0   \n",
       "16496           103     1.0      Very confident        11533.0   \n",
       "16497            36     4.0  Somewhat confident        10739.0   \n",
       "16498            82     6.0      Very confident         7674.0   \n",
       "16499             4     2.0           Confident         9751.0   \n",
       "\n",
       "      counterbalance-o1ql sentence1_model sentence2_model sentence1_type  ...  \\\n",
       "0                set 1_10             all             all              R  ...   \n",
       "1                set 1_10             xlm         trigram              N  ...   \n",
       "2                set 1_10             xlm         electra              S  ...   \n",
       "3                set 1_10             xlm            bert              S  ...   \n",
       "4                set 1_10             xlm         trigram              N  ...   \n",
       "...                   ...             ...             ...            ...  ...   \n",
       "16495             set 1_9         roberta             xlm              N  ...   \n",
       "16496             set 1_9          bigram         roberta              S  ...   \n",
       "16497             set 1_9            gpt2            lstm              S  ...   \n",
       "16498             set 1_9         electra            bert              S  ...   \n",
       "16499             set 1_9             all             all              N  ...   \n",
       "\n",
       "      sentence1_model_targeted_to_accept sentence1_model_targeted_to_reject  \\\n",
       "0                                    NaN                                NaN   \n",
       "1                                    NaN                                NaN   \n",
       "2                                    xlm                            electra   \n",
       "3                                    xlm                               bert   \n",
       "4                                trigram                                xlm   \n",
       "...                                  ...                                ...   \n",
       "16495                                NaN                                NaN   \n",
       "16496                            roberta                             bigram   \n",
       "16497                               lstm                               gpt2   \n",
       "16498                               bert                            electra   \n",
       "16499                                NaN                                NaN   \n",
       "\n",
       "      subject  subject_group  binarized_choice_probability_NC_LB  \\\n",
       "0           0              1                            0.000000   \n",
       "1           0              1                            0.000000   \n",
       "2           0              1                            0.888889   \n",
       "3           0              1                            0.888889   \n",
       "4           0              1                            0.222222   \n",
       "...       ...            ...                                 ...   \n",
       "16495      99              1                            0.222222   \n",
       "16496      99              1                            0.444444   \n",
       "16497      99              1                            0.888889   \n",
       "16498      99              1                            1.000000   \n",
       "16499      99              1                            0.000000   \n",
       "\n",
       "       binarized_choice_probability_NC_UB  majority_vote_NC_LB  \\\n",
       "0                                     0.0                  0.0   \n",
       "1                                     0.0                  0.0   \n",
       "2                                     0.9                  1.0   \n",
       "3                                     0.9                  1.0   \n",
       "4                                     0.2                  0.0   \n",
       "...                                   ...                  ...   \n",
       "16495                                 0.2                  0.0   \n",
       "16496                                 0.4                  0.0   \n",
       "16497                                 0.9                  1.0   \n",
       "16498                                 1.0                  1.0   \n",
       "16499                                 0.0                  0.0   \n",
       "\n",
       "       majority_vote_NC_UB  mean_rating_NC_LB  mean_rating_NC_UB  \n",
       "0                      0.0           1.333333                1.4  \n",
       "1                      0.0           1.666667                1.8  \n",
       "2                      1.0           4.666667                4.8  \n",
       "3                      1.0           4.777778                4.7  \n",
       "4                      0.0           2.444444                2.5  \n",
       "...                    ...                ...                ...  \n",
       "16495                  0.0           2.555556                2.4  \n",
       "16496                  0.0           3.333333                3.1  \n",
       "16497                  1.0           5.000000                4.9  \n",
       "16498                  1.0           5.111111                5.2  \n",
       "16499                  0.0           1.666667                1.7  \n",
       "\n",
       "[16500 rows x 45 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import behav_exp_analysis\n",
    "df = behav_exp_analysis.data_preprocessing()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentence_pair', 'Trial Number', 'rating', 'Response',\n",
       "       'Reaction Time', 'counterbalance-o1ql', 'sentence1_model',\n",
       "       'sentence2_model', 'sentence1_type', 'sentence2_type', 'sentence1',\n",
       "       'sentence2', 'sentence1_gpt2_prob', 'sentence2_gpt2_prob',\n",
       "       'sentence1_roberta_prob', 'sentence2_roberta_prob',\n",
       "       'sentence1_electra_prob', 'sentence2_electra_prob',\n",
       "       'sentence1_bert_prob', 'sentence2_bert_prob', 'sentence1_xlm_prob',\n",
       "       'sentence2_xlm_prob', 'sentence1_lstm_prob', 'sentence2_lstm_prob',\n",
       "       'sentence1_rnn_prob', 'sentence2_rnn_prob', 'sentence1_trigram_prob',\n",
       "       'sentence2_trigram_prob', 'sentence1_bigram_prob',\n",
       "       'sentence2_bigram_prob', 'sentence1_location', 'trial_type',\n",
       "       'sentence2_model_targeted_to_accept',\n",
       "       'sentence2_model_targeted_to_reject',\n",
       "       'sentence1_model_targeted_to_accept',\n",
       "       'sentence1_model_targeted_to_reject', 'subject', 'subject_group',\n",
       "       'binarized_choice_probability_NC_LB',\n",
       "       'binarized_choice_probability_NC_UB', 'majority_vote_NC_LB',\n",
       "       'majority_vote_NC_UB', 'mean_rating_NC_LB', 'mean_rating_NC_UB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcolom = ['sentence_pair', 'Trial Number', 'rating', 'Response', 'Reaction Time', 'sentence1_gpt2_prob', 'sentence2_gpt2_prob']\n",
    "\n",
    "df2 = df[fcolom]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TFGPT2LMHeadModel' from 'transformers' (c:\\Users\\danie\\anaconda3\\envs\\contstimlang\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19504\\434332045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFGPT2LMHeadModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"openai-community/gpt2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFGPT2LMHeadModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"openai-community/gpt2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TFGPT2LMHeadModel' from 'transformers' (c:\\Users\\danie\\anaconda3\\envs\\contstimlang\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "outputs = model(inputs)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatgpt code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.53MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 1.15MB/s]\n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 654kB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [00:51<00:00, 10.6MB/s] \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19504\\1082636230.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"This is a test sentence.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mlog_probability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_log_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Log probability of the sentence:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probability\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19504\\1082636230.py\u001b[0m in \u001b[0;36mcalculate_log_probability\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Calculate log probability of each token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of the sentence: -66.4273452758789\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate log probability of a sentence\n",
    "def calculate_log_probability(sentence):\n",
    "    # Tokenize the sentence\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate output probabilities from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "        logits = outputs[0]\n",
    "    \n",
    "    # Calculate log probability of each token\n",
    "    token_log_probs = torch.log_softmax(logits[0], dim=-1)\n",
    "    \n",
    "    # Get token IDs of the input sentence\n",
    "    input_token_ids = input_ids[0]\n",
    "    \n",
    "    # Sum up log probabilities of tokens in the input sentence\n",
    "    log_prob_sum = 0\n",
    "    for i, token_id in enumerate(input_token_ids):\n",
    "        log_prob_sum += token_log_probs[i, token_id]\n",
    "    \n",
    "    return log_prob_sum.item()\n",
    "\n",
    "# Example usage\n",
    "sentence = \"A message has been sent to your account\"\n",
    "log_probability = calculate_log_probability(sentence)\n",
    "print(\"Log probability of the sentence:\", log_probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Githubcode\n",
    "\n",
    "https://gist.github.com/yuchenlin/eb63e2d0513f70cfc9bb85fa5a78953b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model init\n",
      "3.4872491359710693\n",
      "5.940968036651611\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import OpenAIGPTTokenizer, OpenAIGPTLMHeadModel\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    " \n",
    "def model_init(model_string, cuda):\n",
    "    if model_string.startswith(\"gpt2\"):\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_string)\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_string)\n",
    "    else:\n",
    "        tokenizer = OpenAIGPTTokenizer.from_pretrained(model_string)\n",
    "        model = OpenAIGPTLMHeadModel.from_pretrained(model_string)\n",
    "    model.eval()\n",
    "    if cuda:\n",
    "        model.to('cuda')\n",
    "    print(\"Model init\")\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def sent_scoring(model_tokenizer, text, cuda):\n",
    "    model = model_tokenizer[0]\n",
    "    tokenizer = model_tokenizer[1]\n",
    "    assert model is not None\n",
    "    assert tokenizer is not None\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)  # Batch size 1\n",
    "    if cuda:\n",
    "        input_ids = input_ids.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "    loss, logits = outputs[:2]\n",
    "    sentence_prob = loss.item()\n",
    "    return sentence_prob\n",
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model, tokenizer = model_init('openai-gpt', False) \n",
    "    model, tokenizer = model_init('gpt2', False) \n",
    "    print(sent_scoring((model, tokenizer), \"A message has been sent to your account\", False))\n",
    "    print(sent_scoring((model, tokenizer), \"They are barely able to handle Delhi properly\", False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface code\n",
    "\n",
    "https://discuss.huggingface.co/t/generation-probabilities-how-to-compute-probabilities-of-output-scores-for-gpt2/3175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModelForCausalLM' from 'transformers' (c:\\Users\\danie\\anaconda3\\envs\\contstimlang\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19504\\178256946.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AutoModelForCausalLM' from 'transformers' (c:\\Users\\danie\\anaconda3\\envs\\contstimlang\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\", return_dict_in_generate=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "input_ids = tokenizer(\"A message has been sent to your account\", return_tensors=\"pt\").input_ids\n",
    "\n",
    "generated_outputs = gpt2.generate(input_ids, do_sample=True, num_return_sequences=3, output_scores=True)\n",
    "\n",
    "# only use id's that were generated\n",
    "# gen_sequences has shape [3, 15]\n",
    "gen_sequences = generated_outputs.sequences[:, input_ids.shape[-1]:]\n",
    "\n",
    "# let's stack the logits generated at each step to a tensor and transform\n",
    "# logits to probs\n",
    "probs = torch.stack(generated_outputs.scores, dim=1).softmax(-1)  # -> shape [3, 15, vocab_size]\n",
    "\n",
    "# now we need to collect the probability of the generated token\n",
    "# we need to add a dummy dim in the end to make gather work\n",
    "gen_probs = torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
    "\n",
    "# now we can do all kinds of things with the probs\n",
    "\n",
    "# 1) the probs that exactly those sequences are generated again\n",
    "# those are normally going to be very small\n",
    "unique_prob_per_sequence = gen_probs.prod(-1)\n",
    "\n",
    "# 2) normalize the probs over the three sequences\n",
    "normed_gen_probs = gen_probs / gen_probs.sum(0)\n",
    "assert normed_gen_probs[:, 0].sum() == 1.0, \"probs should be normalized\"\n",
    "\n",
    "# 3) compare normalized probs to each other like in 1)\n",
    "unique_normed_prob_per_sequence = normed_gen_probs.prod(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contstimlang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
